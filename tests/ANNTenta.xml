<?xml version="1.0" encoding="utf-8" ?>
<Test Name="Tenta">
	<TestQuestion Category="Grundläggande">
		<Question>
			Vad säger "no free lunch theorem"?
		</Question>
		<Answer>
			Att ta genomsnittet över alla världar (datamängder/problem) ger att det inte finns någon optimal algoritm. Men, givet en specifik domän så finns det algoritmer som är bättre än andra.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Grundläggande">
		<Question>
			Vad är en aktiveringsfunktion?
		</Question>
		<Answer>
			Anger när en nod "aktiveras". Olika typer är: linjär, tröskel, sigmoid.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Grundläggande">
		<Question>
			Vad är en inlärningsregel?
		</Question>
		<Answer>

		</Answer>
	</TestQuestion>
	<TestQuestion Category="Grundläggande">
		<Question>
			Vad är en topologi?
		</Question>
		<Answer>

		</Answer>
	</TestQuestion>
	<TestQuestion Category="Grundläggande">
		<Question>
			Ange olika typer av inlärningsregler.
		</Question>
		<Answer>
			[ul]
				[li]Supervised: En "lärare" ger det korrekta svaret.[/li]
				[li]Unsupervised: Endast indata är tillgängligt.[/li]
				[li]Reinforcement: Belöning fås som indikator hur "rätt" svaret är.[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Grundläggande">
		<Question>
			Vad innebär generalisering?
		</Question>
		<Answer>
			Att ge rätt svar för indata som inte fanns med under träning.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Grundläggande">
		<Question>
			Ange olika sätt man kan mäta prestandan.
		</Question>
		<Answer>
			[ul]
				[li]Felfrekvensen för träningsdata.[/li]
				[li]Felfrekvensen för ny data.[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Grundläggande">
		<Question>
			Vad innebär överinlärning?
		</Question>
		<Answer>
			Det innebär att nätverket i stället lär sig träningsdatan, istället för den underliggande funktionen.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Grundläggande">
		<Question>
			Vad kan man göra för att undvika överinlärning?
		</Question>
		<Answer>
			[ul]
				[li]Använda sig av mindre gömda noder (om nätverket har flera lager).[/li]
				[li]Stoppa träningen i förtid[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Grundläggande">
		<Question>
			Vad kan man göra för att reducera (pruning) en modells komplexitet?
		</Question>
		<Answer>
			[ul]
				[li]Ta bort onödiga gömda noder.[/li]
				[li]Ta bort svaga vikter.[/li]
			[/ul]Detta kan uppnås genom att inkludera en bestraffning i kostfunktionen.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Grundläggande">
		<Question>
			Vad innebär bias-varians dilemmat?
		</Question>
		<Answer>
			Bias är felet som uppstår på grund av felaktiga antagande i inlärnings algoritmen. Hög bias kan leda till att algoritmen missar relevanta relationer mellan särdrag och faktiskt utdata (underinlärning).

			Variansen är felet som uppstår på grund av känslighet till små variationer i träningsdatan. Högvarians kan leda till överinlärning. 

			Bias-varians dilemmat innebär att man antigen får underinlärning eller överinlärning.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Grundläggande">
		<Question>
			Hur fungerar early stopping?
		</Question>
		<Answer>
			Det kräver att man har en till datamängd, validering mängden (som är en del av originaldatan). Nätverket tränas då tills att felet som uppmätts i validering mängden når ett minimum. I praktiken finns det oftast flera lokala minimums, så då använder man någon form av heuristik för att bestämma när träningen ska avslutas. Exempel är: att ett givet antal följande lokala minimums har påträffas.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Grundläggande">
		<Question>
			Vad innebär regularisation?
		</Question>
		<Answer>
			Det är ett sätt att kontrollera komplexiteten hos en modell. Detta fungerar genom att man introducerar en bestraffing i felfunktionen.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="SingleLayer">
		<Question>
			Vad händer om vi kopplar ihop flera linjära nätverket?
		</Question>
		<Answer>
			Det resulterar fortfarande i ett linjärt nätverk. Det för att om: Låt [math]W_1, W_2, W_3[/math] representera tre viktmatriserna för tre linjära nätverk. De sammankopplade nätverket ges av: [math]W_3(W_2(W_x(x)))=(W_3 * W_2 * W_1) * x[/math] där [math]x[/math] är indata.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="SingleLayer">
		<Question>
			Vad innebär Hebbs inlärningshypotes?
		</Question>
		<Answer>
			Att simultana aktiveringar mellan två neuroner stärker synaptiska anslutningen mellan dem.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="SingleLayer">
		<Question>
			Vad är en Threshold Logic Unit?
		</Question>
		<Answer>
			Det innebär att neuron aktiveras (dvs ger 1 i utvärde) endast om: [math]\sum_i w_i x_i > \theta[/math], annars ges värdet 0 där [math]\theta[/math] är tröskelvärdet. Det får även att modifiera ekvationen så att den istället skrivs som: [math]w_0 * 1 + \sum_i w_i x_i > 0[/math] där [math]w_0 = -\theta[/math].
		</Answer>
	</TestQuestion>
	<TestQuestion Category="SingleLayer">
		<Question>
			Vad innebär det att något är linjärt separerbart?
		</Question>
		<Answer>
			Det innebär att datan kan delas in av en linje (2D) eller ett plan (högre dimensioner) där ena sidan anger första klassen och den andra sidan den andra klassen.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="SingleLayer">
		<Question>
			Hur kan ett trösklat nätverk tränas?
		</Question>
		<Answer>
			Genom att ändra vikter när data klassifieras fel.
			Om resultatet är 0, men borde vara 1 så ändras vikterna: [math]\Delta w = \eta x[/math].
			Om resultatet är 1, men borde vara 0 så ändras vikterna: [math]\Delta w = -\eta x[/math].

			Alternativt: Låt [math]e=t-y[/math] vara felet där [math]t[/math] är det verkliga värdet och [math]y[/math] är resultatet. Då uppdateras vikterna enligt: [math]\Delta w = \eta e x[/math].
		</Answer>
	</TestQuestion>
	<TestQuestion Category="SingleLayer">
		<Question>
			Vad säger konvergenssatsen för perception inlärning?
		</Question>
		<Answer>
			Om det finns en lösning för en ändlig tränings datamängd, så kommer nätverket alltid att konverga efter ett ändligt antal step, oberoende av steglängden [math]\eta[/math].
		</Answer>
	</TestQuestion>
	<TestQuestion Category="SingleLayer">
		<Question>
			Hur fungerar delta regeln?
		</Question>
		<Answer>
			Låt [math]e = t-w^Tx[/math] vara felet (dvs skillnaden mellan verkliga värdet och de värdet som skickas ut.). Sen ska då vikterna hittas som minimerar funktionen: [math]\xi = e^2/2[/math]. En enkel algoritm är då att använda sig av "gradient decent", där gradienten är riktningen där felet öker som måste (och vi tar då motsatt riktning).

			Detta ger att vikterna ska ändras enligt: [math]\Delta w = \eta e x[/math],
		</Answer>
	</TestQuestion>
	<TestQuestion Category="MultiLayer">
		<Question>
			Kan ett flerlagernätverk alltid extrahera ett komplext område?
		</Question>
		<Answer>
			Ja, givet att det finns tillräckligt med gömda noder.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="MultiLayer">
		<Question>
			Varför fungerar inte inlärningsreglerna för enlagersnätverk för flerlagersnätverk?
		</Question>
		<Answer>
			[b]Perceptron inlärning[/b]
			Kräver att vi vet vilken riktning vikterna ska ändras för att komma nära lösningen.

			[b]Delta regeln[/b]
			Kräver att vi kan mäta felet innan vi trösklar. Fungerar endast för de sista lagret.

			Lösningen är att använda en funktion som ser ut som att vi trösklar, men som är deriverbar.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="MultiLayer">
		<Question>
			Ange olika funktioner som används som tröskels funktioner i flerlagersnätverk.
		</Question>
		<Answer>
			Sigmoid (?): [math]\phi(x)=(1-e^-x)/(1+e^-x)[/math].
			Arctan: [math]\phi(x)=arctan(x)[/math].
		</Answer>
	</TestQuestion>
	<TestQuestion Category="MultiLayer">
		<Question>
			Hur fungerar backprop?
		</Question>
		<Answer>
			Den består av tre delar:
			[b]Forward pass[/b]
			Beräkna alla: [math]h_j = \phi(\sum_i v_(j, i) x_i)[/math] och [math]y_k = \phi(\sum_i w_(k, j) h_j)[/math] där [math]h_j[/math] är en gömd nod, [math]v_(j, i)[/math] en vikt i det första lagret (gömda) och [math]y_k[/math] är en utnod, [math]w_(k, j)[/math] en vikt i det andra lagret (output).

			[b]Backward pass[/b]
			Beräkna alla (fel): [math]\delta_k = (t_k - y_k)*\phi'(y_k^text{in})[/math] och [math]\delta_j = \sum_k \delta_k * w_(k, j) * \phi'(h_j^{text}))[/math].

			[b]Uppdatera vikter[/b]
			[math]\delta w_(k, j) = \eta \delta_k h_j[/math] och [math]\delta v_(j, i) = \eta \delta_j x_i[/math].
		</Answer>
	</TestQuestion>
	<TestQuestion Category="MultiLayer">
		<Question>
			Vad för problem finns det med backprop?
		</Question>
		<Answer>
			[ul]
				[li]Konvergerar inte alltid (fastnar i lokalt minimum).[/li]
				[li]Konvergerar segt.[/li]
				[li]Många parameterar måste finjusteras.[/li]
				[li]Skalar dåligt för stora problem.[/li]
				[li]Biologiskt orealistisk.[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="MultiLayer">
		<Question>
			Vad bör man tänka på när man använder sig av backprop?
		</Question>
		<Answer>
			[ul]
				[li]Använd en antisymetrisk [math]\phi(x)[/math] funktion.[/li]
				[li]Lägg målvärderna [math]t[/math] inom samma domän som [math]\phi[/math].[/li]
				[li]Ordna eller vikta träningsexemplerna så att svåra exemplar dominerar.[/li]
				[li]Välj smarta initial vikter.[/li]
				[li]Introducera momentum i vikt uppdateringen.[/li]
				[li]Lägg till slumpmässigt brus till vikterna under träning.[/li]
				[li]Ta bort [math]\phi(x)[/math] funktionen för utnoder.[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="MultiLayer">
		<Question>
			Vad är en "Support Vector Machine" för något?
		</Question>
		<Answer>
			Det är något som transformerar indata till hög-dimensionell rum och väljer den separering som har maximala marginaler.

			[b]Fördelar[/b]
			[ul]
				[li]Mycket bra på att generalisera.[/li]
				[li]Fungerar bra även med liten träningsdata.[/li]
				[li]Snabb klassifikation[/li]
			[/ul][b]Nackdelar[/b]
			[ul]
				[li]Icke-lokala vikt beräkningar.[/li]
				[li]Svårt att implementera effektivt.[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="CompetitiveLearning">
		<Question>
			Vad innebär "Vector Quantization"?
		</Question>
		<Answer>
			Det innebär delar in en mängd punkter (~vektorer) i grupper, där varje grupp ungefär har lika många punkter närmast gruppen. Varje grupp representeras av ett center.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="CompetitiveLearning">
		<Question>
			Vad innebär competitive learning?
		</Question>
		<Answer>
			Det innebär att man endast uppdateras en noden som "vinner".
		</Answer>
	</TestQuestion>
	<TestQuestion Category="CompetitiveLearning">
		<Question>
			Vad är en död nod för något, och vad kan man göra för att undvika att det uppstår?
		</Question>
		<Answer>
			Det innebär att noder som ligger långt ifrån datan aldrig kommer att vinna, och därför ej förbättras. För att undvika att det uppstår kan man t.ex. göra:
			[ul]
				[li]Initialisera noderna m.h.a riktig data.[/li]
				[li]Starta från en punkt.[/li]
				[li]Man låter att alla noder alltid lär sig lite.[/li]
				[li]Man låter att "förlorande" noder vinner lättare.[/li]
				[li]Grannar till vinnaren uppdateras också.[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="CompetitiveLearning">
		<Question>
			Vad är en Radial-basis function (RBF) för något?
		</Question>
		<Answer>
			Det är en funktion, där funktionens värde endast beror på avståndet från ett center (t.ex. origo). Det vill säga: Låt [math]\phi(x)[/math] vara en RBF funktion och [math]vec x[/math] en vektor. Då gäller: [math]\phi(vec x) = \phi(||vec x||)[/math].
		</Answer>
	</TestQuestion>
	<TestQuestion Category="CompetitiveLearning">
		<Question>
			Hur fungerar ett Radial-basis function (RBF) nätverk?
		</Question>
		<Answer>
			Det består av tre lager: inlaget, gömda lagret och utlagret. Varje nod i det gömda lagret har en överföringsfunktion är av typen [i]radial-basis[/i] där varje nod har en position (dess center). Utlagret beräknar sedan utdatan som summan av de [math]n[/math] gömda noderna: [math]hat f(x)=\sum_i^n w_i \phi_i(x)[/math] där [math]hat f(x)[/math] är en approximation av funktionen [math]f(x)[/math].

			Viktern kan antigen beräknas med minstakvadratmetoden eller delta-regeln. För att placera ut RBF-noderna så användas oövervakadinlärning, som t.ex. Competitive Learning eller Expectation Maximization.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="CompetitiveLearning">
		<Question>
			Vad är en Self Organizing Map för något?
		</Question>
		<Answer>
			Det är en avbildning (map) som bevarar topologin inom datan. Dvs om två punkter i indatan är nära varandra, så kommer de även vara nära varandra i avbildningen. Den kan också användas för att reducera dimensionen på indata, från hög-dimensionell till låg (1D, 2D, 3D).

			Den inlärningsprincip som används är "competitive learning" där vinnarens grannar också får ta del på vinsten. Man låter även storleken på grannskapet variera under inlärningsprocessen, där den i början är stort och sedan minskar.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="CompetitiveLearning">
		<Question>
			Hur lyder algoritmen för SOM?
		</Question>
		<Answer>
			[ol]
				[li]Beräkna likheten mellan indataa och vikterna som inkommer vid varje utnod.[/li]
				[li]Hitta den nod som är mest likt, [i]vinnaren[/i].[/li]
				[li]Välj ett antal utnoder som ligger nära vinnaren i utnätet. Detta kallas för grannskapet.[/li]
				[li]Uppdatera vikterna för alla noder i grannskapet så att deras vikter flyttas närmare indatan.[/li]
			[/ol]
			[b]Beräkna likheten[/b]
			Det som oftast används är det euklidiska avståndet mellan indata och vikt vektorn för noden.

			[b]Viktuppdatering[/b]
			Sker enligt: [math]w_i \leftarrow w_i + \eta (x-w_i)[/math] där [math]w_i[/math] är vikt vektorn för den [math]i[/math]:te utnoden.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="DataProcessing">
		<Question>
		
		</Question>
		<Answer>

		</Answer>
	</TestQuestion>
</Test>
