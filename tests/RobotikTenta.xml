<?xml version="1.0" encoding="utf-8" ?>
<Test Name="Tenta">
	<TestQuestion Category="Mobility">
	    <Question>
	    	Vad innebär statisk respektive dynamisk stabilitet?
	    </Question>
	    <Answer>
	    	Att en robot är statisk stabil innebär att den är stabil när den står stilla, medans dynamisk stabilitet betyder att den måste röra på sig för att bli stabil.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Mobility">
	    <Question>
	    	Vad är det huvudsakliga problemen för locomotion?
	    </Question>
	    <Answer>
	    	[b]Stabilitet[/b]
	    	[ul]
	    		[li]Antalet och geometri för kontaktpunkterna.[/li]
	    		[li]Tyngdpunkten.[/li]
	    		[li]Statisk/dynamisk stabilitet.[/li]
	    		[li]Inklination (lutning) för terrängen.[/li]
	    	[/ul][b]Träffytans egenskaper[/b]
	    	[ul]
	    		[li]Kontaktpunktens bana, storlek och form.[/li]
	    		[li]Träffvinkel (angle of contact).[/li]
	    		[li]Friktion.[/li]
	    	[/ul][b]Typ av miljö[/b][ul]
	    		[li]Struktur.[/li]
	    		[li]Medium - vatten, luft, mjukmark, hårdmark.[/li]
	    	[/ul]
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Mobility">
	    <Question>
	    	Vad är för- och nackdelarna med rörelse baserad på ben?
	    </Question>
	    <Answer>
	    	[b]Fördelar[/b][ul]
	    		[li]Kan hantera svår terräng bra.[/li]
	    		[li]Det är endast kontaktpunkterna som behöver vara bra, marken mellan dem spelar ingen roll.[/li]
	    	[/ul][b]Nackdelar[/b][ul]
	    		[li]Mekaniskt komplext.[/li]
	    		[li]Tar mycket kraft.[/li]
	    	[/ul]
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Mobility">
	    <Question>
	    	Vad innebär gait?
	    </Question>
	    <Answer>
	    	Sekvensen av lyft och släpp händelser för individuella ben. Fler ben ger fler möjliga gaits.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Mobility">
	    <Question>
	    	Hur man bör man flytta benen för att det statistiskt sätt ska bli stabilit?
	    </Question>
	    <Answer>
	    	Man ska flytta benen i grupper av tre ben.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Mobility">
	    <Question>
	    	Vad innebär bipeds och quadrupeds?
	    </Question>
	    <Answer>
	    	Bipeds: Två ben.
	    	Quadrupeds: Fyra ben. Blir statistiskt sätt stabilt när roboten står stilla.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Mobility">
	    <Question>
	    	När behövs den upphängning för robotar med hjul?
	    </Question>
	    <Answer>
	    	Typiskt när man har fler än 3 hjul. Annars tappar man kontakt med marken om den inte är perfekt platt.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Mobility">
	    <Question>
	    	Vad är ett "swedish wheel" för något?
	    </Question>
	    <Answer>

	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Mobility">
	    <Question>
	    	Vad innebär det att en robot är "omnidirectional"?
	    </Question>
	    <Answer>
	    	Att roboten kan röra sig i vilken riktning som helst (i planet) oberoende av robotens orientering.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Mobility">
	    <Question>
	    	Vad innebär "slip/skid" styrning?
	    </Question>
	    <Answer>
	    	Det innebär att man svänger genom att ha olika hastigheter på hjulen. Är mycket energi ineffektiv när friktionen är hög.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Mobility">
	    <Question>
	    	Vad är för- och nackdelar med olika typer av flygande robotar?
	    </Question>
	    <Answer>
	    	[b]Fasta vingar (fixed wing)[/b]
	    	[ul]
	    		[li]Kan glidflyga.[/li]
	    		[li]Kan röra sig snabbt.[/li]
	    		[li]Kan ej stå stilla.[/li]
	    		[li]Behöver stor yta för start/landning.[/li]
	    	[/ul][b]Flera rotorer[/b]
	    	[ul]
	    		[li]Kan stå stilla.[/li]
	    		[li]Kan lätt ändra höjd.[/li]
	    		[li]Kan flyga nära marken.[/li]
	    		[li]Behöver liten yta för start/landning.[/li]
	    		[li]Begränsad räckvidd.[/li]
	    	[/ul]
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Mobility">
	    <Question>
	    	Vad krävs det för att kontrollera rörelsen för en robot?
	    </Question>
	    <Answer>
	    	[ul]
	    		[li]Kinematisk/dynamisk modell av roboten.[/li]
	    		[li]Modell för kontakten med marken (mycket komplicerat).[/li]
	    		[li]Definitionen av rörelsen som ska utföras.[/li]
	    		[li]Design av en kontroll metod.[/li]
	    		[li]Verifikationen och finjustering.[/li]
	    	[/ul]
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Mobility">
	    <Question>
	    	Hur lyder den kinematiska modellen för differential drive?
	    </Question>
	    <Answer>
	    	Vi har två hjul, robotens position och orientering i rummet "pose" beskrivs av tre parameterar: [math]x, y, theta[/math]. Vi antar att hjulens radie är den samma ([math]r[/math]) och avståndet mellan de två hjulen är [math]B=2l[/math]. Vi kontrollerar roboten genom att ändra vinkelhastigheten för de respektive hjulen: [math]phi_R, phi_L[/math].

	    	Då blir:
	    	[math]v = r / 2 (phi_R + phi_L), omega = r / B (phi_R - phi_L)[/math]
	    	[math]phi_R = (v + l * omega) / r[/math]
	    	[math]phi_L = (v - l * omega) / r[/math]
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Mobility">
	    <Question>
	    	Vad är holonomy?
	    </Question>
	    <Answer>
	    	En robot är [i]holonomisk[/i] om vi kan kontrollera [i]alla[/i] frihetsgrader. En robot som vi ej kan kontrollera alla frihetsgrader säges vara [i]icke-holonomisk[/i].
	    </Answer>
	</TestQuestion>
		<TestQuestion Category="Mobility">
	    <Question>
	    	Vad är skillnanden mellan en path och en trajectory?
	    </Question>
	    <Answer>
	    	En trajectory är en path med tiden specificerad.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Vad är en sensor?
	    </Question>
	    <Answer>
	    	Något som ger en uppskattning av miljön och robotens tillstånd.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Ange olika klassificeringar som kan göras av sensorer.
	    </Question>
	    <Answer>
	    	Sensorer kan delas in beroende på vad som mäts:
	    	[b]Proprioceptive (PC) sensors[/b]
	    	Mäter värden som är interna för roboten, som t.ex. motorhastighet, riktning, batteristatus.

	    	[b]Exteroceptive (EC) sensors[/b]
	    	Ger information från robotens miljö, som t.ex. avstånd till objekt, ljussättning.

	    	Men det går även att dela in baserat på hur mätningen går till:
	    	[b]Passive (P) sensors[/b]
	    	Energin kommer ifrån miljön, som t.ex. kamera, mikrofon.

	    	[b]Active (A) sensors[/b]
	    	Man skickar ut energi och mäter reaktionen. Detta ger ofta bättre prestanda, men påverkas till viss mån av miljön. Exempel är lasersensorer och sonar.
	    </Answer>
	</TestQuestion>
		<TestQuestion Category="Sensing">
	    <Question>
	    	Vad mäter en encoder?
	    </Question>
	    <Answer>
	    	Den mäter rotationen för ett hjul, men kan också användas för att mätas positionen för en led i en arm. Det finns huvudsakligen två olika typer: inkrementell och absolut. Ofta kallas dessa encoders för rotary eller shaft encoders.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Ange olika metoder som encoders använder sig av.
	    </Question>
	    <Answer>
	    	[b]Optiskt[/b]
	    	Den använder sig av en ljuskälla och en detektor. Ljuskällan skickas genom ett hjul, med hål i. Rotationen mäts då genom att om ljuset går igenom hållet eller inte genererar en puls. En optisk encoder kan oftast ha flera tusen "ticks" per varv.

	    	[b]Magnetiskt[/b]
	    	Använder sig av magnetiskt material på disken istället för hål. Sensorser (som ofta använder sig av hall-effekten) upptäcker när en magnetiskt material passerar. Har ofta mindre upplösning än en optiskt encoder (typiskt mindre än 12), men är billigare.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Hur fungerar en inkrementell encoder?
	    </Question>
	    <Answer>
	    	Genom att använda sig två detektorer, som ligger 90 grader ur fas. Detta genererar två olika pulser. Genom att kolla på tillståndssekvesen, så kan även riktningen för ändringen bestämmas. En encoder som fungerar på detta sätt kallas för en quadrature encoder.

	    	[img]https://dl.dropboxusercontent.com/u/4940720/TentaPluggGenerator/images/IncrementalEncoder.png[/img]  
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Hur fungerar en absolut encoder?
	    </Question>
	    <Answer>
	    	Genom att använda sig av flera olika "varv" av hål. Man skapar då en specifik kod för varje position som läses av.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Vad mäter en potentiometer?
	    </Question>
	    <Answer>
	    	Mäter variabel resistans vilket kan användas för linjär eller vinkelhastighet. Används oftast som kontrol för användare.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Vad är den främsta fördelen med kompasser jämförelse med andra sensorer för att mäta orientering?
	    </Question>
	    <Answer>
	    	Att den mäter orientering i ett absolut koordinat system istället för relativt.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Vad för problem finns det med en kompass?
	    </Question>
	    <Answer>
	    	Är mycket känslig emot andra magnetiska material vilket gör den svårt att använda i miljöer konstruerade av människor.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Vad är (rate) gyroskop för något?
	    </Question>
	    <Answer>
	    	Det är en sensor som mäter rotationshastigheten. För att få orienteringen så kan man integrera värdet. Sensorn beror ofta på temperaturen vilket ger brus som får värdet att avika efter tid.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Vad är en accelerometer?
	    </Question>
	    <Answer>
	   		Den mäter linjär acceleration. Problemet är att den inte kan mäta vinkeln för accelerationen, vilket gör att den inte kan urskilja accelerationen ifrån tyngdkraften. För att få positionen så kan man integrera värdet två gånger. Den är också mycket känslig för brus och kräver att man vet orienteringen så att man kan ta bort tyngdkraften.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Vad mäter en inclinometer?
	    </Question>
	    <Answer>
	    	Lutningen vilket kan göras med olika metoder: accelerometer, gasbubbla i vätska.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Vad innebär cross sensitivity?
	    </Question>
	    <Answer>
	    	Att mätningen av acceleration eller rotationen runt en axel ofta påverkas av andra saker som t.ex. påverkan från andra axlar och att gyroskopet reagerar till acceleration.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Vad är en IMU?
	    </Question>
	    <Answer>
	    	IMU står för [i]inertial measurement unit[/i] och kombinerar accelerator och gyroskop i tre axlar, men kommer också ibland med magnetometers.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Vad är tactila sensorer för något?
	    </Question>
	    <Answer>
	    	Den mäter fysisk interkation med miljön. Exempel är bumper switches och non-contact proximity sensors.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Ange olika typer av bumper switches.
	    </Question>
	    <Answer>
	    	[ul]
	    		[li]Kontakt - om en knapp trycks in.[/li]
	    		[li]Ljus - om en ljustråle bryts.[/li]
	    	[/ul]
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Vad mäter kapacitiva sensorer?
	    </Question>
	    <Answer>
	    	Förändringen i kapacitet. Det används i pekskämar och proximity sensorer. Problemet är att inte alla typer av material kan upptäckas, för det kräver att materialet är ledande.
	    </Answer>
	</TestQuestion>
	<!-- Något om inductive sensors? -->
	<TestQuestion Category="Sensing">
	    <Question>
	    	Hur fungerar Time-of-flight (TOF) för att mäta avstånd?
	    </Question>
	    <Answer>
	    	Man mäter tiden det tar för något att propagera (och komma tillbaka). Detta görs genom att man vet från början hastigheten för det man mäter i mediumet, och då ges avståndet av [math]d=(vt)/2[/math] där [math]v[/math] är hastigheten i mediumet.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Hur fungerar fasdifferans för att mäta avstånd?
	    </Question>
	    <Answer>
	    	Man mäter fasdifferansen ([math]theta[/math]) mellan en reflekterad signalen och den som skickades. Då ges avståndet av: [math]d=(lambda theta) / (4 pi)[/math] där [math]lambda[/math] är våglängden.

	    	Ett problem är att vi [i]inte[/i] kan mäta avstånd som större än [math]lambda / 2[/math] (en faktor 2 för att signalen måste komma tillbaka). Detta ger om våglängden är 10, så kan vi ej avgöra om det faktiska avståndet är 2 eller 32 meter.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Hur fungerar triangulation för att mäta avstånd?
	    </Question>
	    <Answer>
	    	Se bilden nedan, och avståndet ges av: [math]d=(f L) / x[/math].
	    	[img]https://dl.dropboxusercontent.com/u/4940720/TentaPluggGenerator/images/Triangulation.png[/img].
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Vad för problem finns det med ultraljud för att mäta avstånd?
	    </Question>
	    <Answer>
	    	Hastigheten för ljud i luften är mycket liten (343 m/s vid 20 grader), vilket ger en låg sampling rate. Ultraljud är också [i]mycket[/i] känslig för temperaturer, vissa material reflekterar inte heller ljudvågor.
	    </Answer>
	</TestQuestion>
	<!-- Något om sonar?  -->
	<TestQuestion Category="Sensing">
	    <Question>
	    	Vad för problem finns det med använda IR för att mäta avstånd?
	    </Question>
	    <Answer>
	    	Att det finns problem att det inte finns 1-1 mappning mellan utdata ifrån sensor och avstånd, se bild nedan.

	    	[img]https://dl.dropboxusercontent.com/u/4940720/TentaPluggGenerator/images/IR.png[/img]
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Hur fungerar en radar?
	    </Question>
	    <Answer>
	    	Radar står för: Radio Detection And Ranging. Den fungerar så att man skickar ut och tar emot en radiovåg. Om ett material har hög ledningsförmåga ger det en stark reflektion. Många material absorberar inte/reflekterar inte/sprider inte ut signalen, vilket ger den långt avstånd. Radar ger båda avstånd och riktning för flera mål.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Hur fungerar en doppler radar?
	    </Question>
	    <Answer>
	    	När man skickar ut en signal, och den reflekteras av ett mål som rör sig, så kommer signalen som man får tillbaka ha en förändrad frekvens (dopplereffekten). Detta kan användas för att uppskatta hastigheten hos objektet.

	    	Ett problem är att vi upptäcker radial rörelse med respekt till sensorn, dvs rörelse som genererar dopplereffekt i den signal som tas emot.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Hur bestäms positionen av en GPS mottagare?
	    </Question>
	    <Answer>
	    	Med hjälp av time-of-flight och triangulation.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Vad är de huvudsakliga utmaningarna för GPS?
	    </Question>
	    <Answer>
	    	[ul]
	    		[li]Tidssynkronisering mellan olika satelliter.[/li]
	    		[li]Realtids uppdatering av exakt position för satelliter.[/li]
	    		[li]Noggrann mättning av time-of-flight.[/li]
	    		[li]Störningar ifrån andra signaler.[/li]
	    	[/ul]
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Ange fall när GPS inte fungerar.
	    </Question>
	    <Answer>
	    	När man inte få täckning till satelliter, som t.ex. inomhus.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Ifrån hur många satelliter behövs det för att mäta positionen?
	    </Question>
	    <Answer>
	    	Det krävs minst 3 satelliter för att mäta positionen, och en till för att mäta höjden. Desto mer satelliter man får signaler ifrån desto bättre precision får man.
	    </Answer>
	</TestQuestion>
	<!-- Något om GPS Time synchronization? -->
	<TestQuestion Category="Sensing">
	    <Question>
	    	Vad kan man göra för att förbättra precisionen av GPS?
	    </Question>
	    <Answer>
	    	Man kan korrigera med hjälp av lokala stationer, detta kan ge precision i cm klassen.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Vad är RFID för något?
	    </Question>
	    <Answer>
	    	Det står för Radio Frequency Identification och idén är att själva enheten (kallat för tag) inte har något egen kraftkälla. När läsaren skriver/läser data ifrån tagen så skickas energi. Det finns i tre olika klasser:
	    	[ul]
	    		[li]Low Frequency (LF): 120-156 kHz, 10cm avstånd, låg överföringshastighet.[/li]
	    		[li]High Frequency (HF): 13.56 MHz, 0.1-1m avstånd, låg-medel överföringshastighet. Exempel är NFC.[/li]
	    		[li]Ultrahigh Frequency (UHF): 433 MHz, 1-100m avstånd, medel överföringshastighet[/li]
	    	[/ul]Det kan användas för lokalisering genom att taggen innehåller information om positionen som den får när den kommer nära roboten (fingerprinting).
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Hur kan man använda WiFi för att bygga en karta?
	    </Question>
	    <Answer>
	    	Man kan mäta styrkan på den signal man får tillbaka (RSS), detta blir då en feature i en karta. Ofta krävs det mer än en accesspunkt för att det ska fungera.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Hur kan man använda Bluetooth för lokalisering?
	    </Question>
	    <Answer>
	    	Genom att kombinera fingerprinting med RSS.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Sensing">
	    <Question>
	    	Vad mäter Ultra Wide Band (UWB?)
	    </Question>
	    <Answer>
	    	Den mäter avstånd, och finns i två olika typer.
	    	One-way Time Of Arrival (TOA): A skickar ett meddelande med en tidsstämpel som B tar emot. För att uppskatta avståndet så jämför man tiderna. Detta kräver dock att klockorna är mycket bra synkroniserade.

	    	Two-way TOA: A skickar ett meddelande till B vilket behandlar det och skickar tillbaka. A subtraherar bearbetningstiden för B, vilket ger att tiden när A tar emot B signals är 2 gånger tiden för signalen.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Localization">
	    <Question>
	    	Vad innebär dead reckoning?
	    </Question>
	    <Answer>
	    	Det innebär att vi uppskattar den relativa positionen med hjälp av encoders och den kinematiska modellen för roboten. Det är också möjligt att använda sig av en IMU, kamera eller att försöka matcha laserskanning från olika positioner.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Localization">
	    <Question>
	    	Vad är odometri?
	    </Question>
	    <Answer>
	    	Det innebär att vi integrerar encoder mätningarna över tid m.h.a den kinematiska modellen för att uppskatta en robots position och orientering. Desto bättre kinematisk modell man använder sig av, desto bättre odometri får man.

	    	Odometri är oftast mycket noggrant över ett kort avstånd, men kommer ofta börja drifta ifrån den korrekta positionen över tid, och felet är obundet. Fel i vinkeln ger stora fel i positionen.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Localization">
	    <Question>
	    	Ange hur man kan bestämma positionen och orienteringen för en robot som har diffenertial drive som kinematisk modell.
	    </Question>
	    <Answer>
	    	Låt [math]Delta E_R[/math] och [math]Delta E_L[/math] vara skillnaden i mätningar hos encoder över en tid [math]Delta T[/math]. Om [math]K[/math] är skalningsfaktor som omvandlar skillnad i encoder värde till skillnad i vinkel, [math]Delta phi = K Delta E[/math], då ges hastigheterna av: [math]v = (r / 2 (K Delta E_R + K Delta E_L)) / (Delta T), omega = (r / B (K Delta E_R - K Delta E_L)) / (Delta T)[/math].

	    	Då kan man beräkna [math]D = text{Ändring i sträcka} = v Delta T = r / 2 (K Delta E_R + K Delta E_L)[/math] och [math]Delta theta = text{Ändring i orientering} = omega Delta T = r / B (K Delta E_R - K Delta E_L)[/math].

	    	Detta ger att positionen och orientering kan uppskattas som:
	    	[math]x(k+1)=x(k) + D*cos(theta)[/math]
	    	[math]y(k+1)=y(k) + D*sin(theta)[/math]
	    	[math]theta(k+1)=theta(k+1)+Delta theta[/math].
 	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Localization">
	    <Question>
	    	Hur kan man beskriva osäkerhet i odometri?
	    </Question>
	    <Answer>
	    	Som brus som appliceras på mätningarna:
	    	[math]x(k+1)=x(k)+(v*dt+Phi_D) * cos(theta)[/math]
	    	[math]y(k+1)=y(k)+(v*dt+Phi_D) * sin(theta)[/math]
	    	[math]theta(k+1)=theta(k)+(omega*dt+Phi_(theta, omega)) + Phi_(theta, v)[/math]
	    	där [math]Phi_D, Phi_(theta, omega), Phi_(theta, v)[/math] oftast antas vara normalfördelade med noll i väntevärde: [math]N(0, sigma^2)[/math].
 
	    	[math]sigma^2[/math] modelleras som något som beror på vinkelhastigheten:
	    	[math]Phi_D = N(0, (v * dt * k_D)^2)[/math]
	    	[math]Phi_(theta, v) = N(0, (v * dt * k_v)^2)[/math]
	    	[math]Phi_(theta, omega) = N(0, (omega * dt * k_(omega))^2)[/math]
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Localization">
	    <Question>
	    	Ange olika källor för fel i odometri.
	    </Question>
	    <Answer>
	    	[b]Systematiska fel[/b]
	    	[ul]
	    		[li]Fel storlek av hjulen i modellen.[/li]
	    		[li]Hjulen ligger ej i linje.[/li]
	    		[li]Begränsad encoder upplösning och sampling rate.[/li]
	    	[/ul][b]Icke-systematiska fel[/b]
	    	[ul]
	    		[li]Om marken ej är platt leder det till hjul rör sig kortare/längre.[/li]
	    		[li]Andra objekt på marken ger stora fel.[/li]
	    		[li]Hjulen glider[/li]
	    		[li]Externa krafter, som t.ex. att hjulet ej rör marken vid endast en punkt.[/li]
	    	[/ul]
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Localization">
	    <Question>
	    	Vad innebär kidnappingsproblemet inom lokalisering?
	    </Question>
	    <Answer>
	    	Det innebär att roboten "kidnappas" och placeras på något annat ställe. Roboten måste då först upptäcka att den har blivit kidnappad, och sedan utföra global lokalisering.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Localization">
	    <Question>
	    	Hur kan vi formellt definiera lokaliserings problemet?
	    </Question>
	    <Answer>
	    	Låt [math]x[/math] vara robotens tillstånd (position och orientering), [math]z[/math] vara en observation och [math]u[/math] var kontroll input. Då gäller det att [math]p(x_(k+1) | x_k, x_(k-1)) = p(x_(k+1)|x_k), p(z_k | x_k), p(x_(k+1) | x_k, u_(k + 1))[/math].

	    	Detta innebär om vill bestämma robotens tillstånd vid tidpunkten [math]k+1[/math] så innehåller tillståndet vid tidpunkten [math]k[/math] all information om tidigare tillstånd. Det gäller även att mätningarna vid tidpunkt [math]k[/math] endast beror på tillståndet vid den tidpunkten och att tillståndet vid tidpunkt [math]k+1[/math] beror endast på tillståndet vid tidpunkten [math]k[/math] och kontroll inputen.

	    	Då blir estimeringen baserad på en kontroll input [math]u_k[/math]:
	    	[math]p(x_(k+1) | Z_k, U_k) = int p(x_(k+1) | u_k, x_k) p (x_k | X_k, Y_k) dx_k[/math] där [math]p(x_(k+1) | z_k, u_k)[/math] är den rörelsemodell som oftast ges av odometri.

	    	Uppdateras med nya mätningar [math]z_(k+1)[/math] enligt:
	    	[math]p(x_(k+1) | Z_(k+1), U_k) = eta p(z_(k+1) | x_(k+1)) p(x_(k+1) | Z_k, U_k)[/math] där [math]p(z_(k+1) | x_(k+1))[/math] är modellen för mätningarna och [math]eta[/math] en normaliserings konstant.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Localization">
	    <Question>
			Ange olika sätt för att representera den probabilistiska informationen för lokaliserings problemet.
	    </Question>
	    <Answer>
	    	[b]Normalfördelning[/b]
	    	Med hjälp av en normalfördelning. Ett problem är att man ej kan representera en fördelning som är "multi modal", dvs. har flera "kullar".

	    	[b]Gaussian Mixture Model[/b]
	    	Problemet med "multi-modal" kan lösas genom att man kombinerar flera olika normalfördelningar.

	    	[b]Diskretisering[/b]
	    	Delar upp fördelningen i små delar.

	    	[b]Sampling[/b]
	    	Se nästan fråga.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Localization">
	    <Question>
	    	Hur fungerar ett partikelfilter för lokalisering?
	    </Question>
	    <Answer>
	    	Ett partikelfilter representerar fördelningen m.h.a. av en mängd partiklar [math]p_k={ x_k, pi_k }[/math], som är samplade ifrån fördelningen. Varje partikel representerar en hypotes om tillståndet. Partikelns vikt, [math]pi_k[/math], initialiseras som [math]1/N[/math] där [math]N[/math] är antalet partiklar.

	    	Ekvationen för filtret ges av: [math]p(x_(k+1) | Z_(k+1), U_(k+1)) = eta int p(x_(k+1) | x_k, u_(k+1)) p(x_k | Z_k, U_k) dx_k[/math]. Filtret approximera detta genom att för varje nytt tillstånd uppskatta den m.h.a rörelsemodellen [math]p(x_(k+1) | x_k, u_(k+1))[/math] (se frågan om odometri).

	    	När man uppskattar tillståndet så kommer partiklarna att sprida sig, dvs. osäkerheten kommer att öka. För att minska osäkerheten så kan man använda sig av en IMU eller att kalibrera odometrin, för att begränsa felet så måste man använda sig av mätningar av miljön.

	    	Filtret approximerar uppdaterings ekvationen: [math]p(x_(k+1) | Z_(k+1), U_(k+1)) = eta p(z_(k+1) | x_(k+1)) p(x_(k+1) | Z_k, U_(k+1))[/math] genom att för varje partikel multiplicera vikten med likelihood för mätningarna: [math]p(z_(k+1) | x_(k+1))[/math].

	    	När partiklarna sprider sig (vilket det alltid kommer göra pga. brus i rörelsemodellen), så kommer allt färre partiklar vara i regioner där [math]p(x_k | Z_k, U_k)[/math] är stor, dvs. att approximationen har blir dålig. För att hantera det, så kan man resampla.

	    	Detta innebär att man skapar en ny mängd av partiklar, där sannolikheten att kopiera en partikel ifrån den gamla mängden till den nya är proportionerlig  till dess vikt (man kan även ha flera kopior av partiklar). Vikten för partikeln återställs även till [math]1/N[/math].
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Localization">
	    <Question>
	    	Vad för egenskaper partikelfilter för lokalisering?
	    </Question>
	    <Answer>
	    	[ul]
	    		[li]Kan representera en godtycklig fördelning givet tillräckligt antal partiklar.[/li]
	    		[li]Kan hantera "multi-modal" utan problem.[/li]
	    		[li]Kan hantera icke-linjära system.[/li]
	    		[li]Kan vara beräkningsintensiv för vissa applikationer.[/li]
	    		[li]Precisionen beror på antalet partiklar.[/li]
	    		[li]Problem med högre dimensioner - antalet partiklar växer exponetiellt med antalet dimensioner.[/li]
	    	[/ul]
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Localization">
	    <Question>
	    	Hur fungerar Kalmanfiltret?
	    </Question>
	    <Answer>
	    	Låt [math]x_k = f(x_(k-1), u_(k-1), w_(k-1))[/math] vara systemets dynamik (rörelsemodellen), [math]z_k=h(x_k, v_k)[/math] vara mätmodellen. Vi antar även att att bruset är normalfördelat: [math]p(w) = N(0, Q), p(v) = N(0, R)[/math].

	    	Vi kan sedan inte veta värdet för bruset, så vi antar att det är 0 för våra uppskattningar: [math]bar x_k = f(hat x_(k-1), u_(k-1), 0), bar z_k = h(hat x_k, 0)[/math].

	    	Vi kan sedan linjärisera systemet:
	    	[math]x_k ~~ bar x_k + A(x_(k-1) - hat x_(k-1)) + W w_(k-1)[/math]
	    	[math]z_k ~~ bar z_k + H(x_k - hat x_k + V v_(k-1)[/math]
	    	där [math]A, W, H, V[/math] är Jacobianer.

	    	För att estimera positionen gör vi följande:
	    	[math]hat x_k = f(bar x_(k-1), u_(k-1), 0), P_k^(-) = A_k P_(k-1) A_k^T W_k Q_(k-1) W_k^T[/math]

	    	För att uppdatera mätningarna för vi följande:
	    	[ol]
	    		[li]Beräkna Kalman gain: [math]K_k = P_k^(-) H_k^T (H_k P_k^(-) H_k^T + V_k R_k V_k^T)^(-1)[/math].[/li]
	    		[li]Uppdatera uppskatningen med mätningen [math]z_k[/math]: [math]hat x_k = hat x_k^(-) + K_k (z_k - h(hat x_k^(-1), 0))[/math][/li]
	    		[li]Uppdatera fel kovariansen: [math]P_k = (I - K-k H_k) P_k^(-)[/math].[/li]
	    	[/ol]
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Localization">
	    <Question>
	    	Vad för egenskaper av EKF lokalisering?
	    </Question>
	    <Answer>
	    	[ul]
	    		[li]Mycket effektiv att beräkna.[/li]
	    		[li]Har använts i många olika områden för en lång tid.[/li]
	    		[li]Skalar väl till flera dimensioner.[/li]
	    		[li]Finns inga teoretiska garantier att systemet konvergerar om systemet är icke-linjärt, men fungerar bra i praktiken.[/li]
	    		[li]Kan ej hantera "multi-modal" fördelningar.[/li]
	    		[li]Linjärisering blir problematiskt när systemet är osäkert med hänsyn till icke-linjäriteten.[/li]
	    		[li]Behöver en bra initialvärden för att konvergera.[/li]
	    	[/ul]
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Mapping">
	    <Question>
	    	Vad innebär SLAM?
	    </Question>
	    <Answer>
			För att skapa en karta, behöver vi veta positionen. Men ofta vet vi inte positionen, utan behöver en karta för att bestämma den. Denna innebär att vi bör göra båda samtidigt - bestämma positionen och kartan. Detta är idén bakom SLAM - Simultaneous Localization and Mapping.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Mapping">
	    <Question>
	    	Ange olika sätt att representera kartan.
	    </Question>
	    <Answer>
			Det finns i huvudsakligen två olika riktningar: topologisk och metrisk. För metriska, är de två vanligaste representationerna features och occupancy grids.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Mapping">
	    <Question>
	    	Hur fungerar ett occupancy grid?
	    </Question>
	    <Answer>
				I ett occupancy grid så delar man upp världen i celler, där kartan definierar för varje cell om den är upptagen eller inte. Det är också möjligt att man representerar det med en sannolikhet istället, där 0 betyder definitivt fri och 1 upptagen.

				[b]Fördelar[/b]
				[ul]
					[li]Kräver ingen modell (model free).[/li]
					[li]Bra sätt för att hantera osäkerdata.[/li]
					[li]Modellerar explicit det fria utrymmet.[/li]
					[li]Visuellt komplett.[/li]
				[/ul][b]Nackdelar[/b]
				[ul]
					[li]Begränsad upplösning.[/li]
					[li]Kräver ofta mer beräkningar.[/li]
				[/ul]
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Mapping">
	    <Question>
	    	Hur fungerar en feature (landmark) karta?
	    </Question>
	    <Answer>
			Kartan representeras av en mängd av features: [math]M = { m_k | j = 1, ..., M }[/math], där exempel på features är punkter, linjer, plan, hörn, kanter, etc.

			[b]Fördelar[/b]
				[ul]
					[li]Kompakt.[/li]
					[li]Hög precision.[/li]
				[/ul][b]Nackdelar[/b]
			[ul]
				[li]Gles representation, modellerar ej det fria utrymmet[/li]
				[li]Behöver veta vilka features som behövs användas som prior.[/li]
			[/ul]
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Mapping">
	    <Question>
	    	Hur fungerar en topologisk karta?
	    </Question>
	    <Answer>
			Kartan representeras av en graf, där varje hörn representerar en plats och kanterna mellan hörnen betecknar dörrar, trappor, etc.

			[b]Fördelar[/b]
				[ul]
					[li]Skalar bra med storleken av miljön.[/li]
					[li]Kan skapas utan krav att veta den exakta geometrin.[/li]
					[li]Lätt att göra path planning.[/li]
			[/ul][b]Nackdelar[/b]
			[ul]
				[li]Informationen för postionen är väldigt grov.[/li]
				[li]Kräver att roboten kan upptäcka vilken plats den är i, vilket i praktiken är mycket svårt.[/li]
			[/ul]
    	</Answer>
	</TestQuestion>
	<TestQuestion Category="Mapping">
	    <Question>
	    	Hur fungerar EKF SLAM?
	    </Question>
	    <Answer>
			Det är samma idé som för EKF för lokalisering, men att vi nu också låter landmarks vara en del av tillståndsvektorn. Detta ger att tillståndsvektorn växer med tiden. Det är ofta problem med konsistens pga. osäkerhet och icke-linjäritet.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Mapping">
	    <Question>
	    	Kan man använda ett partikelfilter för SLAM?
	    </Question>
	    <Answer>
			Det är ofta inte en bra lösning, för att partikelfilter skalar dåligt med antalet dimensioner (antalet features i det här fallet).
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Mapping">
	    <Question>
	    	Vad är Rao-blackwellized particle filter (RBPF)?
	    </Question>
	    <Answer>
			Den kombinerar styrkan hos Kalmanfiltret (skalbarheten) med partikelfiltret (hanterar "multi-modal" fördelningar). Det fungerar så att man marginaliserar ut den linjära delen representerar den med en normalfördelning och låter partikelfiltret hantera de icke-linjära delarna.

			Man låter då varje partikel både representera pose och innehålla en karta. Då blir givet en pose, så blir landmarks okorrelerade.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Mapping">
	    <Question>
	    	Vad är en pose graf?
	    </Question>
	    <Answer>
			Det är en algoritm för SLAM. Man kan formulera mappningsproblemet som ett graf optimeringsproblem istället. Då låter man ett hörn i grafen representera posen för där en sensoravläsning gjordes och begräsningar ifrån odometrin och mätningar bli kanter.

			Sedan använder man sig av icke-linjära optimeringar för att hitta den optimala grafen, det vill säga den optimala positionen för roboten och landmarks.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Navigation">
	    <Question>
	    	Vad för steg ingår i global motion planning?
	    </Question>
	    <Answer>
	    	[ol]
	    		[li]Generera en representation av kartan som kan används vid planering.[/li]
	    		[li]Definiera en avståndsfunktion.[/li]
	    		[li]Utför en sökning ifrån start konfigurationen till slut konfigurationen.[/li]
	    	[/ol]
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Navigation">
	    <Question>
	    	Vad är configuration space?
	    </Question>
	    <Answer>
	    	Det är mängden av alla konfigurationer. Varje pose representeras av en punkt i denna rymd och dimensionen av rymden ges av antalet frihetsgrader.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Navigation">
	    <Question>
	    	Vad är Voronoi diagram för något?
	    </Question>
	    <Answer>
	    	Det är ett sätt att dela upp (partitionera) en rymd. Det fungerar så att vi definierar olika punkter (t.ex. städer), kallat för generatorer. Sedan delar vi upp rymden så att varje punkt i rymden tillhör en generator som den är närmast till.

	    	Detta kan användas för att göra path planning, genom att hitta den kortaste vägen längs kanterna. Fördelen är att algoritmen blir enkel och kan användas för att kontrollera roboten. Nackdelen är att den väg som hittas är den längsta möjliga.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Navigation">
	    <Question>
	    	Vad är visibility graph för något?
	    </Question>
	    <Answer>
	    	Den fungerar så att man kopplar ihop hörn av rymden genom att endast skapa kanter mellan hörnen om de kan "se varandra", dvs. det existerar ingen kollision mellan dem. Sedan kan man använd en grafsöknings algoritm för att hitta vägen. Detta genererar den kortaste vägen, men försöker vara så nära som möjligt till hindren. Detta ger algoritmen små marginaler för fel i rörelsen.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Navigation">
	    <Question>
	    	Hur fungerar cell decomposition?
	    </Question>
	    <Answer>
	    	Det fungerar så att man delar in det fria utrymmet (free space, F) till regioner som är sammankopplade, som kallas för celler. Man skapar sedan en graf där en kant existerar mellan cellerna om det finns "öppet" utrymme mellan dem.

	    	Varje rätlinjig väg inom en cell är garanterad att inte kollidera med ett hinder om dekompositionen är exakt. Fungerar bra för glesa miljöer.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Navigation">
	    <Question>
	    	Hur kan man approximera en cell decomposition?
	    </Question>
	    <Answer>
	    	Genom t.ex. använda sig av ett occupancy grid.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Navigation">
	    <Question>
	    	Hur kan man skapa en adaptiv cell decomposition?
	    </Question>
	    <Answer>
	    	Med hjälp av ett quad-tree i 2D eller oct-tree i 3D.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Navigation">
	    <Question>
	    	Hur fungerar wavefront propagation?
	    </Question>
	    <Answer>
	    	Sätt 0 för målet, och lägg till 1 till varje granne och expandera likt en våg tills att du når starten.

	    	[img]https://dl.dropboxusercontent.com/u/4940720/TentaPluggGenerator/images/WavefrontPropagation.png[/img]
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Navigation">
	    <Question>
	    	Vad är D* för algoritm?
	    </Question>
	    <Answer>
	    	Det är en algoritm som gör det möjligt att göra lokala förändringar för en väg som A* har skapat.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Navigation">
	    <Question>
	    	Vad för problem finns det med algoritmer som använder sig av celler för path planning?
	    </Question>
	    <Answer>
	    	[ul]
	    		[li]För nära hinder.[/li]
	    		[li]Den genererade vägen är justerad med hänsyn till rutnätet och är ofta inte jämn.[/li]
	    		[li]Vägen är inte den kortaste.[/li]
	    	[/ul]
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Navigation">
	    <Question>
	    	Vad kan man göra för att göra en väg mer jämn?
	    </Question>
	    <Answer>
	    	Man kan jämna ut rutnätet med t.ex. en normalfördelad kernel detta ger att kostanden för att gå nära hinder blir högre. Det går även att jämna ut själva vägen genom att försöka koppla ihop två kanter i vägen om de går att gå direkt mellan dem utan kollision.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Navigation">
	    <Question>
	    	Vad för nackdelar finns det med sample baserad path planning algoritmer?
	    </Question>
	    <Answer>
	    	Det finns inga garantier att algoritmen kommer hitta en lösning (om den existerar). Det bästa man kan få är att när antalet iterationer i algoritmen går emot oändligheten så går sannolikheten att algoritmen hittar en lösning emot 1.
	    </Answer>
	</TestQuestion>
<!-- 	<TestQuestion Category="Navigation">
	    <Question>
	    	Hur fungerar Rapidly Exploring Random Trees (RRT)?
	    </Question>
	    <Answer>

	    </Answer>
	</TestQuestion> -->
	<TestQuestion Category="Navigation">
	    <Question>
	    	Hur fungear potential fields?
	    </Question>
	    <Answer>
	    	Idén är att låta roboten vara en partikel i ett fält med potential, [math]U(x)[/math]. Man låter då målet vara något som attraherar roboten och där hinder stöter bort roboten. Då låter man kraften som roboten attraherars av i varje plats i fältet vara [math]F(x)=-grad U(x)[/math].

	    	Nackdelarna med denna metod är att rörelsen ofta inte blir jämn, rörelsen oscillerar, den fastnar i lokala minimum och kräver att man finjusterar parametrarna för att de ska fungera bra.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Navigation">
	    <Question>
	    	Hur fungerar ett Vector field histogram (VFH)?
	    </Question>
	    <Answer>
	    	Man beräknar kraften för att undvika hinder på ett liknande sätt som potential fields. Man genererar sedan ett histogram där x-värdet anger med den vinkeln som hindret upptäcktes med och y-värdet sannolikheten att det faktiskt fanns ett hinder i den riktningen.

	    	Sedan identifierar man alla möjliga öppningar som roboten kan komma genom, och sedan väljer man den öppningen som kostnadsfunktionen [math]G=alpha * text{target_direction} + b * text{wheel_orientation} + c * text{previous_direction}[/math] har lägst värdet.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Navigation">
	    <Question>
	    	Hur fungerar dynamic window approach (DWA)?
	    </Question>
	    <Answer>
	    	Man väljer hastigheter [math](v, omega)[/math] som kan nå inom ett givet tidsrymd och dynamiska begräsningar.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Navigation">
	    <Question>
	    	Hur fungerar Bubble (Elasti) band?
	    </Question>
	    <Answer>
	    	Man stänger i roboten i en "bubbla" och försöker koppla ihop start och mål med bubblor. Bubblornas storlek expanderas sedan i riktningen emot hindren.
	    </Answer>
	</TestQuestion> 
	<TestQuestion Category="Vision">
	    <Question>
	    	Vad innebär intrinsic kameraparameterar?
	    </Question>
	    <Answer>
	    	[ul]
	    		[li]Principal point (mitten av bilden): [math](u_0, v_0)[/math].[/li]
	    		[li]Brännvidd: [math](f_x, f_y)[/math][/li]
	    		[li]Hur x och y-axlarna är förvrängade mellan varandra (skew): [math]gamma[/math][/li]
	    		[li]Linsförvrängning[/li]
	    	[/ul]Detta sammanfattas av: [math]A = [[(f_x), gamma, (u_0)], [0, (f_y), (v_0)], [0, 0, 1]][/math].
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Vision">
	    <Question>
	    	Vad innebär extrinsic kameraparameterar?
	    </Question>
	    <Answer>
	    	Hur kameran är roterad och förflyttad i verkliga världen.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Vision">
	    <Question>
	    	Vad anger kameramatrisen?
	    </Question>
	    <Answer>
	    	Den kombinerar de extrinsic och intrinsic parametrarna, av en [math]3 \times 4[/math] matris i homogenakoordinater. [math]C = A[R T][/math] där [math]R[/math] är rotationen för kameran och [math]T[/math] förflyttningen.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Vision">
	    <Question>
	    	 Vad innebär kamerakalibrering?
	    </Question>
	    <Answer>
	    	Det innebär att vi använder bilder med kända mönstrer för att estimera kameraparametrarna.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Vision">
	    <Question>
	    	Vad innebär lens distortion?
	    </Question>
	    <Answer>

	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Vision">
	    <Question>
	    	Vad för två komponenter består lens distortion av?
	    </Question>
	    <Answer>
	    	Radial och tangential. Radial är ofta 1-2 magnituder större än tangential.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Vision">
	    <Question>
	    	Hur kan man beräkna avståndet ifrån stereo vision?
	    </Question>
	    <Answer>
	    	Avståndet ges av baseline, brännvidd och disparity (skillnanden i bildposition): [math]Z=b * f / (x_1 - x_2)[/math]. En disparity map visar skillnanden mellan varje pixel.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Vision">
	    <Question>
	    	Hur kan man beräkna avståndet med hjälp av ljus?
	    </Question>
	    <Answer>
	    	Genom att projicera ett känt mönster.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Vision">
	    <Question>
	    	Hur kan man beräkna avståndet med hjälp av fokus?
	    </Question>
	    <Answer>
	    	Genom att kameran endast fokuserar på en del av bilden och genom att kontrollera fokusen så ser man hur mycket objektet i fråga är i fokus, vilket ger avståndet.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Vision">
	    <Question>
	    	Hur kan man beräkna field of view?
	    </Question>
	    <Answer>
	    	Vertikal: [math]2 tan^-1((height) / (2f))[/math]
	    	Horisontell: [math]2 tan^-1((width) / (2f))[/math]
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Vision">
	    <Question>
	    	Vad för problem finns det med kameror med stor synvinkel (field of view)?
	    </Question>
	    <Answer>
	    	Det leder till att bilden blir förvrängd.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Vision">
	    <Question>
	    	Vad för olika synvinklar finns det till att klassificera objekt?
	    </Question>
	    <Answer>
	    	[b]Features (keypoints)[/b]
	    	[ul]
	    		[li]Extrahera features från en träningsbild och skapa en modell.[/li]
	    		[li]För en ny bild, extrahera features och försök att matcha dessa till modellen.[/li]
	    	[/ul][b]Template[/b]
	    	[ul]
	    		[li]Hitta en bild av det objekt som du vill identifiera senare (template).[/li]
	    		[li]I en ny bild, hitta matchningar mellan template och bilden genom korrelation.[/li]
	    	[/ul][b]Deep learning[/b]
	    	[ul]
	    		[li]Annotera träningsdata.[/li]
	    		[li]Träna ett NN med många lager.[/li]
	    		[li]Skicka in en bild i nätverket för att klassificera.[/li]
	    	[/ul]
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Vision">
	    <Question>
	    	Vad är en keypoint?
	    </Question>
	    <Answer>
	    	Det är en typ av feature och består av två delar: interest point detector (vart den är) och descriptor (hur den ser ut).
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Manipulation">
	    <Question>
	    	Ange de olika delarna i en manipulator (t.ex. arm).
	    </Question>
	    <Answer>
	    	[img width="75%" height="75%"]https://dl.dropboxusercontent.com/u/4940720/TentaPluggGenerator/images/Manipulator.png[/img]
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Manipulation">
	    <Question>
	    	Vad innebär forward kinematics?
	    </Question>
	    <Answer>
	    	Det innebär att vi mappar ifrån konfigurationsrymden till den kartesiskarymden, [math]r = F(phi)[/math].
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Manipulation">
	    <Question>
	    	Vad innebär inverse kinematics?
	    </Question>
	    <Answer>
	    	Det innebär att vi mappar ifrån den kartesiskarymden till konfigurationsrymden, [math]phi = F^-1(r)[/math].
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Manipulation">
	    <Question>
	    	Vad är "workspace" för något?
	    </Question>
	    <Answer>
	    	Det är den delrymden av den kartesiskarymden som roboten faktiskt kan nå.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Manipulation">
	    <Question>
	    	Vad är DH parameterar för något?
	    </Question>
	    <Answer>
	    	Det är ett sätt att härleda forward / inverse kinematics genom transformationer mellan homogena koordinatsystem.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Manipulation">
	    <Question>
	    	Vad för problem finns det med inverse kinematics?
	    </Question>
	    <Answer>
	    	Det är ofta fallet att [math]n > m[/math], dvs. dimensionen för konfigurationsrymden är högre än den kartesiskarymden. Detta leder till att [math]phi = F^-1(r)[/math] har flera lösningar.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Manipulation">
	    <Question>
	    	Hur fungerar en numeriskmetod för att hitta forward / inverse kinematics?
	    </Question>
	    <Answer>
	    	Vi börjar ifrån forward kinematics [math]x(t)=F(theta(t))[/math]. Sedan deriverar vi: [math]dot x(t) = (dF(phi(t))) / dt = J(theta) dot phi(t)[/math]. Sen övergår vi till differenskvot:
	    	[math]Delta x ~~ J(phi) Delta phi[/math]
	    	[math]Delta phi ~~ J^(***)(phi) Delta x[/math]
	    	där [math]J^(***)[/math] är pseudoinversen: [math]J^(***)=(J^T J)^-1 J^T[/math].

	    	De fall där [math]rank(J(phi)) lt m[/math] kallas för singularitet och innebär att det inte är möjligt att röra sig i den riktningen. Nollrymden för denna Jacobian är de ändring av konfigurationen som ej resulterar i en förändring av pose.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Manipulation">
	    <Question>
	    	Vad händer om vi gör en rakrörelse i konfigurationsrymden?
	    </Question>
	    <Answer>
	    	Det leder ofta inte till att armen kommer röra sig i rakt, pga. kinematiken ofta inte är linjär.
	    </Answer>
	</TestQuestion>
	<TestQuestion Category="Manipulation">
	    <Question>
	    	Vad för krävs mer än kinematics för att flytta på en arm?
	    </Question>
	    <Answer>
	    	Armen kan kollidera med miljön eller överstiga begräsningar på lederna. Detta innebär att vi måste planera rörelsen för en arm.
	    </Answer>
	</TestQuestion>
</Test>
