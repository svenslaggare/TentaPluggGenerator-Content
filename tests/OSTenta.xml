<?xml version="1.0" encoding="utf-8" ?>
<Test Name="Tenta">
	<TestQuestion Category="Processer">
		<Question>
			Vad är en process?
		</Question>
		<Answer>
			En process är ett program under exekvering.
			En process brukar innehålla följande information:
			[ul]
				[li]Kod (även känt som "text")[/li]
				[li]Data (globala variabler, BSS, stack, heap)[/li]
				[li]Registerinnehåll (som t.ex. programräknaren)[/li]
				[li]Fildeskriptorer (dvs öppna filer)[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Processer">
		<Question>
			Varför används processmodellen?
		</Question>
		<Answer>
			På grund av att ett program underkörning har inkapslas av en process så blir det lättare att tillåta multiprogrammering, dvs att flera program kör "samtidigt". Det ger även bättre feltolerans vilket innebär om en process kraschar så behöver ej hela operativsystemet krascha.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Processer">
		<Question>
			Hur skapas nya processer i UNIX system?
		</Question>
		<Answer>
			Nya processer skapas med hjälp av systemanropet [i]fork()[/i] vilket skapar en kopia av den körande processen. Vanligtvist vill man att en den nya processen kör ett annat program, vilket görs med systemanrop ur familjen [i]exec[/i] vilket byter ut den nuvarande programmet emot ett annat.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Processer">
		<Question>
			På vilka sätt kan en process terminera?
		</Question>
		<Answer>
			En process kan termineras på fyra sätt:
			[ul]
				[li]Normalt programslut (frivilligt)[/li]
				[li]Med fel som programmet upptäckt (frivilligt)[/li]
				[li]Fatalt fel (ofrivilligt)[/li]
				[li]Dödas av en annan process[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Processer">
		<Question>
			Vad är skillnaden mellan en förgrundsprocess och bakgrundsprocess (i UNIX)?
		</Question>
		<Answer>
			En process som körs i förgrunden är den process som man arbetar interaktivt med medans en process som körs i bakgrunden arbetar man ej interaktivt med. Det går även se det som att när en process körs i förgrunden finns det en annan process (föräldern) som väntar på att den ska avslutas medans när den körs i bakgrunden så väntar ingen process.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Processer">
		<Question>
			Vad är en "daemon" i UNIX?
		</Question>
		<Answer>
			Det är en bakgrundsprocess. Dessa processer utför oftast system åtgärder,
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Processer">
		<Question>
			Ange de tillstånd som en process kan vara i.
		</Question>
		<Answer>
			Det finns tre tillstånd: Running, Blocked och Ready.
			[img width="50%" height="50%"]https://dl.dropboxusercontent.com/u/4940720/TentaPluggGenerator/images/ProcessStates.png[/img]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Processer">
		<Question>
			Vad för abstraktion används för att hålla reda på processer i systemet?
		</Question>
		<Answer>
			En så kallad [i]processtabell[/i] där varje process blir en post i tabellen som kallas för Process Controll Block (PCB). Information som lagras i denna post är process ID, prioritet, tillstånd, register, text, data, osv.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Processer">
		<Question>
			Vad är en "zombie" process?
		</Question>
		<Answer>
			Det är en process som har körts klart, men som fortfarande har en post i processtabellen. Varför det kan uppstå är på grund av att göra det möjligt för föräldrarprocesser att veta varför en barnprocess terminerade. Posten frigörs genom att anropa [i]wait[/i] på processen som terminerade.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Minneshantering">
		<Question>
			Vad innebär dynamisk laddning och dynamisk länkning?
		</Question>
		<Answer>
			Dynamisk laddning innebär att ett program (eller bibliotek) laddas in i den nuvarande processens minne [b]efter den har startat[/b].
			Dynamisk länkning innebär att mapping av namn till adress för symboler sker [b]efter kompilering[/b].
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Minneshantering">
		<Question>
			Vad innebär en fysik och en logisk adressrymd?
		</Question>
		<Answer>
			En fysisk adressrymd är de faktiska minnespositioner i datorns fysiska primärminne.
			En logisk adressrymd är en abstrakt addressrymd som programmet använder, vilket mappas till den fysiska adressrymden. Ett annat namn är en [i]virutell addressrymd[/i].
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Minneshantering">
		<Question>
			Vad innebär relokerbar kod?
		</Question>
		<Answer>
			Det innebär adresser anges relativt något, vanligtvist början av programmet. De relativa adresserna binds till en absolut adress när vi vet var programmet ska laddas in. Dessa tillfällen är:
			[ul]
				[li]Compile-time[/li]
				[li]Load-time[/li]
				[li]Run-time[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Minneshantering">
		<Question>
			Vad innebär fragmentering?
		</Question>
		<Answer>
			Det finns två typer av fragmentering:
			[b]Extern fragmentering[/b]
			Det finns ledigt utrymme, men är uppdelat i för små block (som ej är närliggande). Extern fragmentering löses med kompaktering (vilket är kostsamt) eller att endast ha en enda blockstorlek, vilket leder till intern fragmentering.

			[b]Intern fragmentering[/b]
			Dålig utnyttjande av minne inom allokerade block. Detta löses med variabel blockstorlek, vilket leder till extern fragmentering.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Minneshantering">
		<Question>
			Ange två sätt att hålla reda på ledigt minne.
		</Question>
		<Answer>
			[b]Länkande listor[/b]
			Elementen i listan består av hål (ledigt utrymme) där varje hål innehåller: Startadress, storlek och pekare till nästa element.	Hur listan skall sorteras beror på vilken allokeringsmetod som används.

			[b]Bitmap[/b]
			Minnet delas upp i lika stora "allokeringsenheter" där en bitvektor används där 0 betyder att enheten är ledig och 1 upptagen för enhet [i]i[/i]. Val av storleken på allokeringsenheten blir då viktig där för liten innebär att bitmappen blir för stor medans en för står leder till intern fragmentering.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Minneshantering">
		<Question>
			Vad innebär swappning?
		</Question>
		<Answer>
			Det innebär att en process flyttas mellan primärminne och disk för att ge rum till andra processer. Swap-in innebär att en process flyttas från disk till minne och swap-out innebär att en process flyttas från minne till disk.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Minneshantering">
		<Question>
			Vad innebär ett minnet är sidindelat?
		</Question>
		<Answer>
			Det innebär att minnet delas i lika stora sidor. En sida är något som finns i den virtuella minnesrymden medans en ram är en sida som finns i det fysiska minnet. Översättningen till fysisk address sker vid körning.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Minneshantering">
		<Question>
			Hur fungerar rättigheter (läsa/skriva/exekvera) för minnesadresser i ett sidindelat minne?
		</Question>
		<Answer>
			Rättigheterna fungerar på sidnivå. Detta innebär att t.ex. text och data arean [i]inte[/i] kan dela sidor. Detta är för att text arean vill vi endast kunna läsa och exekvera medans data arean vill vi [i]ej[/i] kunna exekvera!
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Minneshantering">
		<Question>
			Hur kan man undvidka att en process adressar en ram som ej ligger i dess adressrymd?
		</Question>
		<Answer>
			[ol]
				[li]Valid/invalid bit för varje post i sidtabellen.[/li]
				[li]Register som anger längden av sidtabellen.[/li]
			[/ol]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Minneshantering">
		<Question>
			Vad är en TLB för något?
		</Question>
		<Answer>
			TLB står för "Translation Lookaside Buffer" och fungerar som ett cacheminne för sidtabellen som implementeras i hårdvaran (närmare bestämt MMU). En TLB mappar ifrån ett sidnummer till ett ramnummer. Den implementeras med assocativt minne vilket innebär att det går att söka i hela minent parallellt.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Minneshantering">
		<Question>
			Vad innebär en miss i TLBn?
		</Question>
		<Answer>
			Det innebär att den sida som efterfrågas ej finns i TLB. Detta innebär att sidtabellen som finns i primärtminnet måste accessas. Efter det så uppdateras TLB (om sidan var giltig) genom att slänga ut en ogiltig eller gammal post. För de flesta arkitekturer sker hantering i MMU men i vissa arkitekturer som t.ex. SPARC sker det i mjukvara. Detta är för att det mycket komplext vilket tar upp mycket utrymme i hårdvåran.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Minneshantering">
		<Question>
			Ange olika sätt att implementera sidtabellen.
		</Question>
		<Answer>
			[b]En-nivås sidtabell[/b]
			Antag att vi har en logisk adressrymd med storleken [math]2^m[/math] och storleken på en sida är [math]2^n[/math]. Då används de [math]n[/math] första bitarna för att offseten inom sidan, [math]d[/math] och de resterande [math]m-n[/math] bitarna, [math]p[/math] anger vilken sida det är.

			Då kan vi hämta (i sidtabellen) vilket ram som adressen tillhör. När vi har ramnumret och offseten, kan vi hämta den fysiska adressen.

			[b]Fler-nivåers sidtabell[/b]
			Då består sidtabellen av flera nivåer. Syftet med en fler-nivåers sidtabell är att undvika att allokera alla möjliga sidpr för sidtabellen, vilket kan ta upp mycket utrymme och är opraktiskt för 64-bits system. För att få en rimlig storlek på den yttersta sidtabellen krävs minst 5-7 nivåer, men detta blir istället för ineffektivt.

			Exempel:
			Antag att vi har en tvånivåers sidtabell. Om vi antar att vi har en logisk adressrymd med storleken [math]2^m[/math], sidstorleken [math]2^n[/math] och storleken på en post i sidtabellen: [math]2^e[/math]. Den inre sidtabellen kommer då att ha [math]2^(n-e)[/math] poster per sida och den yttre sidtabellen kommer då att ha [math]2^(m-2n-e)[/math] positioner.

			[b]Hashad sidtabell[/b]
			Fungerar som en hashtabell, där vi mappar ifrån sidnummer till en post i sidtabellen. Här kan krockar i tabellen hanteras som länkade listor, dvs alla poster med samma hash bildar en länkad list.

			[b]Inverterad sidtabell[/b]
			Om varje process har en egen sidtabell kan det gå åt mycket minne. Idén med en inverterad sidtabell är ha endast en sidtabell för alla processer där det finns en post för varje fysisk ram. I varje post har man då sidnummret + ID för processen som allokerat ramen.

			Nackdelen med denna implementation är att man måste söka i hela sidtabellen för att hitta ramen för en sida. Detta kan återgärdas genom att t.ex. hasha den inverterade sidtabellen eller använda som av assocativt minne (som dock är dyrt). En annan nackdel är att det blir svårare att dela sidor mellan processer.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Minneshantering">
		<Question>
			Vad innebär demand paging?
		</Question>
		<Answer>
			Det innebär att man lägger till information till sidtabellen som indikerar om sidan finns i primärminnet eller inte. När en sida som inte finns i primärminnet refereras så genereras ett [b]sidfel (page fault)[/b]. Vid sidfel så hämtas sidan ifrån sekundärminnet (t.ex. disk) till primärminnet och sidtabellen uppdateras.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Minneshantering">
		<Question>
			Vad är skillnanden mellan swapping och paging?
		</Question>
		<Answer>
			Swapping innebär att byta ut hela processer medans paging handlar om att byta ut sidor.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Minneshantering">
		<Question>
			Vad innebär pre-paging?
		</Question>
		<Answer>
			Det innebär att vi försöker räkna ut vilka sidor som kommer att behövas och laddar in dessa i förvag.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Sidutbytesalgoritmer">
		<Question>
			Generellt sätt, vilka två mål finns när det kommer till att byta ut sidor?
		</Question>
		<Answer>
			[ol]
				[li]Minimera antalet sidfel.[/li]
				[li]Minimera I/O.[/li]
			[/ol]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Sidutbytesalgoritmer">
		<Question>
			Vad är I/O kostnaden för att byta ut sidor?
		</Question>
		<Answer>
			Det kostar mindre att byta ut en sida som inte är modifierad än en som är modifierad. Dvs: Om en sida i en ram är [b]ren[/b] (ej modiferad) så finns en kopia på disk, vilket innebär att man ej behöver skriva innehållet i ramen till disk, dvs endast 1 I/O operation krävs. Men om en ram är modifierad ([b]dirty[/b]) så måste den skrivas ut till disk innan en ny sida kan läsas in till ramen, dvs 2 I/O operationer krävs.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Sidutbytesalgoritmer">
		<Question>
			Vad innebär en referenssträng?
		</Question>
		<Answer>
			Det är en sträng av sidnummer i den ordning de refereras. Om samma sida har refereras flera gånger i följd, så tas endast en med. En referenssträng kan användas för att utvärdera sidutbytesalgoritmer.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Sidutbytesalgoritmer">
		<Question>
			Vad är ett working set?
		</Question>
		<Answer>
			Den uppsättning sidor som en process refererar, dvs behöver för att kunna exekevera under en (liten) tidsrymd [math]T[/math]. Det mest intressanta med working set är dess storlek. Om en process inte har tillgång till så många ramar som storleken på dess working set så kommer det att genereras många sidfel. 
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Sidutbytesalgoritmer">
		<Question>
			Hur fungerar den optimala sidutbytesalgoritmen?
		</Question>
		<Answer>
			Den sida som kommer att dröja längst innan den refereras igen kommer att bytas ut. Den är optimal med avseende på antalet sidfel och är omöjlig att implementera i praktiska system.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Sidutbytesalgoritmer">
		<Question>
			Hur fungerar FIFO (som sidutbytesalgoritm)?
		</Question>
		<Answer>
			Om inga lediga rammar finns så kommer den sida som har legat längst i primärminnet att bytas ut. Nackdelen med denna algoritm är att en sida som kan användas kan slängas ut. Den kan också ge fler sidfel om man [b]ökar[/b] antalet tillgängliga ramar (Belady's anomali). Den har använts i t.ex. VAX/VMS och Windows NT.

			FIFO = First In First Out.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Sidutbytesalgoritmer">
		<Question>
			Vad är en stackalgoritm (när det kommer till sidutbytesalgoritmer)?
		</Question>
		<Answer>
			Det är en algoritm med egenskapen att den ger färre sidfel när antalet ramar ökas. Det som är karaktäristisk för en stackalgoritm är att för varje referens i en referenssträng är den mängd av sidor som finns i primärmännet givet [math]m[/math] ramar en delmängd av den mängd sidor som finns i minnet givet [math]m+1[/math] ramar.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Sidutbytesalgoritmer">
		<Question>
			Hur fungerar LRU (som sidutbytesalgoritm)?
		</Question>
		<Answer>
			Den sida som det gått längst sedan den refererades kommer att bytas ut. Det är den närmaste approximation av den optimala som kan vi (enkelt) kan göra. Den är dock dyrbar att implementera för det krävs en räknare för varje instruktion som exekveras och kräver en sökning för att hitta sidan som ska slängas ut.

			LRU = Least Recently Used.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Sidutbytesalgoritmer">
		<Question>
			Hur fungerar Clock (som sidutbytesalgoritm)?
		</Question>
		<Answer>
			Det är en enkel approxmation av LRU genom en utvidgning av FIFO. Här införs en referens-bit i sidtabellen. Denna bit nollställs då en sida laddas in och ett ett-ställs när någon byte i sidan adresseras.

			Den fungerar så att en cirkulär lista med alla sidor i primärminnet är ordnad i FIFO ordning. När en sida behövs bytas ut så gör man en sökning i listan och:
			[ul]
				[li]Om sidans referensbit är satt, nollställ den och sök vidare.[/li]
				[li]Första sidan med en nollställd referensbit är den sida som ska bytas ut.[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Sidutbytesalgoritmer">
		<Question>
			Hur fungerar Clock med NRU (som sidutbytesalgoritm)?
		</Question>
		<Answer>
			Det är en förbättring av Clock algoritmen genom att en modifierad-bit införs i sidtabellen. Den är från början nollställd då sidan laddas in. Den ett-ställs då man skriver till någon byte i sidan.

			Den fungerar som Clock men man väljer att byta ut en sida baserat på paret (referensbit, modifierad-bit):
			[ol]
				[li][math](0, 0)[/math] varken refererad eller modifierad.[/li]
				[li][math](0, 1)[/math] inte nyligen använd - men modifierad.[/li]
				[li][math](1, 0)[/math] nyligen använd - men inte modifierad.[/li]
				[li][math](1, 1)[/math] både nyligen använd och modifierad.[/li]
			[/ol]
			Används i Mac.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Sidutbytesalgoritmer">
		<Question>
			Hur fungerar Aging (som sidutbytesalgoritm)?
		</Question>
		<Answer>
			Det är en approximation av LRU. Det fungerar genom att man försöker uppskatta när en sidan senaste referades. Detta görs genom att:
			[ul]
				[li]Till varje post i sidtabellen lägg till en [i]n[/i]-bitars räknare.[/li]
				[li]Regelbundet, t.ex. vid varje klockavbrott, för alla sidor i minnet:
					[ul]
						[li]Skifta räknaren ett steg åt höger.[/li]
						[li]Addera referensbiten för sidan i den vänstra biten i räknaren.[/li]
					[/ul]
				[/li]
				[li]Vid sidfel så väljs sidan med lägst värde på räknaren att bytas ut.[/li]
				[li]Kräver sökning.[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Sidutbytesalgoritmer">
		<Question>
			Hur fungerar WSClock (som sidutbytesalgoritm)?
		</Question>
		<Answer>
			Här försöker man göra en uppskattning av working set. Här bestämer vi en tidsrymd [math]T[/math] för vilket working set ska uppskattas. Datan om sidor i primärminnet är organiserad på samma sätt som för Clock-algoritmen.

			Det funngerar genom att man lägger till en tidsstämpel för varje post i sidtabellen och vid:
			[b]Uppdatering av referensbit[/b]
			Sker regelbundet som t.ex. vid varje klockavbrott vilket nollställer alla referensbitar.

			[b]Sidfel[/b]
			[ul]
				[li]Gå genom alla poster i sidtabellen.[/li]
				[li]Om referensbiten är satt: nollställ och uppdatera tidsstämpeln.[/li]
				[li]Om en sida med nollställd referensbit hittas och den referares längre tillbacka i tiden än [math]T[/math] tidsenheter, dvs den är inte längre i working set:
					[ul]
						[li]Om modifierad-biten är satt - schemalägg att sidan ska skrivas till disk och leta vidare.[/li]
						[li]Om sidan är ren - läs in den nya sidan till denna ram.[/li]
					[/ul]					
				[/li]
				[li]Om man inte hittar en ren sida som inte ligger i working set på ett varv så finns två möjligheter: 
					[ul]
						[li]En skrivning har schemalagts - fortsätta leta - till slut blir en sida ren.[/li]
						[li]Annars ersätt en godtycklig ren sida - om ingen sådan finns ta en godtycklog sida och släng ut.[/li]
					[/ul]
				[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Sidutbytesalgoritmer">
		<Question>
			Vad är en paging daemon?
		</Question>
		<Answer>
			Det är en process som går i bakgrunden om utför två uppgifter:
			[ul]
				[li]När I/O enheten för att skriva sidor till sekundärminnet är ledig skriver modiferade sidor.[/li]
				[li]Om det finns för få ledia ramar så släng ut en del sidor. Information om vilken sida som låg i ramen bör även sparas så om sidan refereras och ramen ej har laddat in en annan sida så kan den återanvändas.[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Sidutbytesalgoritmer">
		<Question>
			Varför vill man kunna "låsa" vissa sidor i minnet?
		</Question>
		<Answer>
			Det beror huvudsakligen av två skäl: effektivitet och att om koden som hanterar pagning byts ut, så kan inga nya sidor laddas in.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Sidutbytesalgoritmer">
		<Question>
			Vad är en lokal och global sidutbytesalgoritm?
		</Question>
		<Answer>
			[b]Lokal[/b]
			Letar endast efter sidor att slänga ut hos processen som fick sidfel.

			[b]Global[/b]
			Algoritmen kan välja vilken sida som helst att slänga ut.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Sidutbytesalgoritmer">
		<Question>
			Vad inenbär thrashing?
		</Question>
		<Answer>
			Om processen spenderar mer tid på att byta sida än att exekverera.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Sidutbytesalgoritmer">
		<Question>
			Vad kan vi göra för att motverka thrashing?
		</Question>
		<Answer>
			Om en process får låg sidfelsfrekvens så ta ifrån den ramar.

			[b]Lokal sidutbytesalgoritm[/b]
			Om en process får en hög sidfelfrekvens:
			[ul]
				[li]Om det finns lediga ramar: låt den allokera flera.[/li]
				[li]Om det inte finns ledia ramar: swappa ut den.[/li]
			[/ul][b]Global sidutbytesalgoritm[/b]
			Om systemet får en hög sidfelfrekvens:
			[ul]
				[li]Försök frigöra ramar.[/li]
				[li]Går det inte: swappa ut processer.[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Minneshantering">
		<Question>
			Hur kan man öka effektiveten för anropen fork och exec i system med sidindelat minne?
		</Question>
		<Answer>
			Istället för att kopiera föräldrarprocessens sidor så kopieras endast sidtabellen. Sidorna markeras då "copy-on-write" vilker innebär om en sida ändras av någon process så kopieras den.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Minneshantering">
		<Question>
			När fungerar virtuellt sidindelat minne dåligt?
		</Question>
		<Answer>
			Om vi har för dålig lokalitet så kan det ge följande problem:
			[ul]
				[li]Många TLB-missar - ger sämre prestanda för att varje minnesaccess som ger upphov till en TLB-miss tar ungefär dubbelt så lång tid som om vi hade fått en träff istället.[/li]
				[li]Kan också ge stort working-set vilket kan leda till många sidfel som tar lång tid att hantera (längre än en TLB-miss)[/li]
			[/ul]Om man överlastar systemet så att working-set inte ryms i minnet vilket leder till thrasing.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Filsystem">
		<Question>
			Ange olika accessmetoder.
		</Question>
		<Answer>
			[b]Sekvensiell access[/b]
			Man läser/skriver en följd av bytes utan möjlighet att kunna positionera sig i filen. Ett exempel är I/O mot tangentbord.

			[b]Random access[/b]
			Man kan positionera sig i filen för skriving/läsning. T.ex. som en hårddisk.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Filsystem">
		<Question>
			Vad för accesskontroll finns det på ett UNIX system?
		</Question>
		<Answer>
			För varje fil/katalog så kan rättigheter anges för tre olika domäner: User, Group, Other (alla användare). Det finns tre rättigheter: [b]r[/b]ead, [b]w[/b]rite och e[b]x[/b]ecute.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Filsystem">
		<Question>
			Varför tillåter man oftast inte cykler i katalogstrukturer?
		</Question>
		<Answer>
			[ul]
				[li]Det blir svårare att göra vanliga operationer som t.ex. att lista innehåller i en katalog och dess underkataloger.[/li]
				[li]Det kan behövas att man har en skrämpsamlare som tar hand om filer som inte kan ej komma åt. Om cykel får existera blir detta svårare.[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Filsystem">
		<Question>
			Vad krävs innan ett filsystem kan användas?
		</Question>
		<Answer>
			Det måste monteras.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Filsystem">
		<Question>
			Ange metoder för att hantera allokering av utrymme för filer.
		</Question>
		<Answer>
			[b]Kontinuerlig allokering[/b]
			Det innebär att hela filen är allokerad i en linjär sekvens av bytes. Detta kan leda till fragmentering och problematisk att hantera filer som växer i storlek. Det används dock för filsystem som endast skrivs en gång, som t.ex. CD-ROM, DVD.

			[b]Blockindelad allokering[/b]
			Skivminnet delas in i lika stora block där blocken antingen hålls reda av en:
			[ul]
				[li]Länkad lista med pekare till nästa block.[/li]
				[li]En separat tabell med pekare till blocken som hålls i minnet. Även känt som File Allocation Table (FAT).[/li]
			[/ul][b]Indexerad allokering[/b]
			Här sparar vi information i en nod, även kallad i-nod om vilka block som tillhör en specifik fil/katalog. I i-noden sparas även metadata som t.ex. ägaren, senast skapad, storlek, osv. Används i UNIX system.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Filsystem">
		<Question>
			Vad för datastrukturer finns normalt sätt i ett filsystem?
		</Question>
		<Answer>
			[b]På disk[/b]
			[ul]
				[li]Master Boot Record (en per disk) - Anger vilket som är den aktiva partitionen. Programmet som finns på MBR laddar in boot blocket.[/li]
				[li]Boot block - Det första blocket vilket är ett program som laddar in OS som finns på partitionen.[/li]
				[li]Superblock - Anger hur partitonen är indelad i block, vilka ledia block det finns osv.[/li]
				[li]File Control Blocks - i-noder.[/li]
				[li]Eventuella katalogstukturer[/li]
			[/ul][b]I minne[/b]
			[ul]
				[li]Partitionstabell: Information on monterade partitioner.[/li]
				[li]Tabell med nyligen accesade kataloger[/li]
				[li]Tabell över alla öppna filer med kopior av filernas FCB:er.[/li]
				[li]Per process öppenn filtabel.[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Filsystem">
		<Question>
			Varför måste filer öppnas/stängas?
		</Question>
		<Answer>
			Öppna filen: För att kontrollera accessrätigheter.
			Stänga filen: Om filen buffrats i minne så behövs bufferten skrivas till disk.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Filsystem">
		<Question>
			Hur håller man ordning på ledia block på disken?
		</Question>
		<Answer>
			[ul]
				[li]Bitvektor (växer med diskstorleken och minskar med blockstorleken).[/li]
				[li]Länkade listor. Dessa kan byggas in i de lediga blocken, vilket inte kräver något extra utrymme (utom pekaren givetvist).[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Filsystem">
		<Question>
			Vad är en mjuk och hård länk?
		</Question>
		<Answer>
			En [i]länk[/i] är en fil som innehåller sökvägen till en annan fil eller katalog.

			[b]Hård länk[/b]
			Hård länkar som skapas av användare får endast peka ut filer för att undvika cykler. När en hård länk skapas så uppdateras räknaren i den utpekade filens [b]i-nod[/b] som anger hur många som refererar till filen. En fil kan inte tas bort så länge denna räknare är större än 0. Det finns alltid minst en hård länk till varje fil/katalog.

			[b]Mjuk länk[/b]
			En mjuk länk får peka ut både filer och kataloger. En mjuk länk påverkare [i]ej[/i] räknaren i i-noden.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Filsystem">
		<Question>
			Ange olika typer av backups som kan göras på ett filsystem.
		</Question>
		<Answer>
			[b]Fysisk[/b]
			Skriver alla block i följd till mediumet som backup görs på.

			[b]Logisk (inkrementell)[/b]
			Skriver endast alla filer/kataloger som har ändras till mediumet. I t.ex. UNIX så följs ej mjuka länkar när backup görs.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Filsystem">
		<Question>
			Ange olika typer av konsistenskontroller som kan göras på ett filsystem.
		</Question>
		<Answer>
			[b]Block konsistens[/b]
			Kontrollerar att alla diskblock finns [b]en[/b] gång i antingen listan över fria block, i en fil eller i listan med dåliga block.

			[b]Filsystemskonsistens[/b]
			Kontrollerar att räknaren för hur många som refererar till en fil stämmer överens med hur många referenser som finns från katalogstrukturen.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Filsystem">
		<Question>
			Vad för datastruktur har kärnan för öppna filer i ett UNIX system?
		</Question>
		<Answer>
			För varje process så finns en tabell över fildeskriptorer. En fildeskriptor är ett heltal, som pekar ut en post i tabellen över öppna filer som delas av alla processer. Tabellen innehåller t.ex. position i filen och pekare till i-noden.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="IO">
		<Question>
			Ange de två huvudklasserna av I/O enheter.
		</Question>
		<Answer>
			[b]Block-devices[/b]
			Läser och skriver block data. Typiska operationer är: read, write och seek. Exempel på enheter är diskar och CD-romar.

			[b]Character-devices[/b]
			Skriver/läser en ström av tecken. Typiska operationer är: put och get. Exempel på enehter är tangentbord och nätverksenheter.

			Det finns andra enheter som t.ex. klockor som ej passar in i dessa klasser. Av effektivitetsskäl så brukar nätverksenheter implementeras med andra operationer.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="IO">
		<Question>
			Ange de två typer av I/O som kan utföras.
		</Question>
		<Answer>
			[b]Blockerade (synkron)[/b]
			Procseesen som begärt I/O väntar till dess att I/O operationen är klar. Oftast är läsning blockerade.

			[b]Icke-blockerader (asynkron)[/b]
			Processen som begärt I/O väntar inte på att I/O operationen ska bli klar. Oftast är skrivning icke-blockerade.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="IO">
		<Question>
			Ange olika sätt att styra I/O enheter.
		</Question>
		<Answer>
			[b]Minnesmappad I/O[/b]
			Det innebär så mappas kontroll- och dataregisters adresser ifrån enheten in i den vanliga adressrymden. Det innebär att skrivning/läsning fungerar genom att en adress skrivs/läses.

			[b]Ports[/b]
			Varje I/O enhet får ett portnummer. Kontrollregistret för enheten läses/skrivs med speciella I/O instruktioner.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="IO">
		<Question>
			Ange olika sätt för att vänta på I/O ska bli klart.
		</Question>
		<Answer>
			[b]Programstyrd I/O (polling)[/b]
			I/O enheten signalerar att den är klar genom att sätta en bit i ett av dess kontrollregister. Programmet som utfört I/O ligger sedan i en loop och läser av kontrollregistret för att upptäcka när I/O enheten är klar. 

			Det är bra att använda när det behövs väntas kort tid på att enheten ska bli klar eller att det kostar för mycket för att ha avbrott eller DMA. Nackdelen med denna metod är att det belastar CPU. Om minnesmappad I/O används så får ej sidan som innehåller adressen där kontrollregistret mappats in cachas. Får då upptäcker man inte när enheten blir klar.

			[b]Avbrottstyrd I/O[/b]
			I/O enheten signalerar att den är klar genom att generera ett avbrott. En avbrottsrutin fångar sedan upp avbrottet och kontrollerar eventuella fel och ser till att en eventuellt blockerad process som cäntar på I/O hamnar i ready-kön. Nackdelen med avbrott är att det kostar hantera på grund av processbyte till avbrottshanteraren i kärnan krävs.

			[b]Direct Memory Access (DMA)[/b]
			Det innebär att en hårdvaruenhet kan överföra en mängd data till/från primärminnet och någon I/O enhet. Vid läsning går datan som läses in först till kernel-space som sedan kopieras till processens adressrymd. Vid skrivning så kopieras data ifrån processen till kernel-space. Onödig kopiering vid överföring kan undvikas genom att mappa om sidorna i sidtabellen.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Avbrott">
		<Question>
			Vad för regel finns det för vad en avbrottsrutin får göra?
		</Question>
		<Answer>
			[ul]
				[li]Får ej påverka processen som avbröts.[/li]
				[li]Måste bli klar snabbt.[/li]
				[li]Får ej vänta på något.[/li]
				[li]Kan inte bli blockerad.[/li]
				[li]Får inte generera sidfel.[/li]
				[li]Får inte utföra systemanrop.[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Avbrott">
		<Question>
			Vad innebär precisa och icke-precisa avbrott?
		</Question>
		<Answer>
			[b]Precisa avbrott[/b]
			Hårdvaran sparar undan ett väldefinerat tillstånd då avbrottet inträffade.

			[b]Icke-precist avbrott[/b]
			Avbrottsrutinen får reda ut tillståndet som t.ex. eventuella halvt utförda instruktioner etc.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="IO">
		<Question>
			Vad är en drivrutin?
		</Question>
		<Answer>
			Det är något som ger ett enklare gränsnitt mot hårdvaran och det OS:set som tillhandahåller ett väldefinerat gränsitt mot drivrutinerna. En drivrutin anropas indirekt av systemanrop.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="IO">
		<Question>
			Vad innebär major och minor device number när det kommer till I/O enheter i UNIX?
		</Question>
		<Answer>
			Major device number: identifierar drivrutinen som används.
			Minor device number: identifierar enheten om drivrutinen hanterar flera enheter.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="TrådarOchMultiprocessorer">
		<Question>
			Vad är en tråd?
		</Question>
		<Answer>
			En tråd kan ses som en lättviktsprocess som delar adressrymd med de andra trådarna i samma process. En tråd innehåller bland annat:
			[ul]
				[li]Programräknare.[/li]
				[li]Register.[/li]
				[li]Stack.[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="TrådarOchMultiprocessorer">
		<Question>
			Vad innebär en context switch?
		</Question>
		<Answer>
			Det innebär att spara ner och återstålla tillståndet för en process eller tråd så att exekveringen kan fortsätt vid ett senare tillfälle.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="TrådarOchMultiprocessorer">
		<Question>
			Vad innebär preemptive (avbrytade) schemaläggning?
		</Question>
		<Answer>
			Det innebär att schemaläggaren kan avbryta en tråd som körs och återuppta den vid ett senare tillfälle.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="TrådarOchMultiprocessorer">
		<Question>
			Hur fungerar trådar som är implementerade i user-space?
		</Question>
		<Answer>
			Då är trådoperationerna biblioteksrutiner där trådarna schemaläggs av run-time systemet. All hantering av trådar (skapa/dödade/terminade) sköts av biblioteksrutiner och run-time systemet.

			Fördelarna med trådar i user-space är det krävs mindre context switches och ett trådbyte kan ske utan systemanrop. Nackdelarna är om ett tråd blockeras så blockeras hela processen (inklusive alla andra trådar i processen). Det går även inte att uppnå sann parallellitet på multiprocesser och schemaläggningen är oftast icke avbrytade (none-preemptive).
		</Answer>
	</TestQuestion>
	<TestQuestion Category="TrådarOchMultiprocessorer">
		<Question>
			Hur fungerar trådar som är implementerade i kernel-space?
		</Question>
		<Answer>
			Då är trådoperationerna systemanrop där trådarna schemaläggs av kärnan. All trådhantering hanteras via systemanrop och av kärnan.

			Fördelarna med trådar i kernel-space är att de kan schemaläggs preemptiv. Om en tråd blockeras kan en annan tråd i samma process schemaläggas. Det går även att schemalägga olika trådar på olika processer för att uppnå sann parallellitet på multiprocesser. Nackdelarna är att trådoperationer är systemanrop som tar länge att utföra på grund av att context switchar behövs göras.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="TrådarOchMultiprocessorer">
		<Question>
			Ange hur man kan kombinera trådar i user-space och i kernel-space.
		</Question>
		<Answer>
			Man kan t.ex. mappa flera trådar i user-space till en tråd i kernel-space.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="TrådarOchMultiprocessorer">
		<Question>
			Vad är en trådpool och varför vill man använda sig av det?
		</Question>
		<Answer>
			En [i]trådpool[/i] är en grupp av trådar som när en tråd i poolen ej exekvererar ligger och sover. Istället för att skapa en ny tråd så låter man en tråd ifrån poolen att "vakna upp" för att utföra arbetet. Syftet med detta är att man vill minimera kostnanderna för att skapa trådar, vilet kan ta upp en stor del om arbetet som ska utföras är kort.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="TrådarOchMultiprocessorer">
		<Question>
			Varför är det problematisk att utföra [i]fork[/i] och [i]exec[/i]] i flertrådadesystem?
		</Question>
		<Answer>
			Det är för när en tråd utför [i]fork[/i] så finns det två val:
			[ol]
				[li]Den nya processen får en tråd.[/li]
				[li]Den nya processen blir en exakt kopia av den gamla med lika många trådar.[/li]
			[/ol]När det kommer till [i]exec[/i] så är det vanligast att hela processen (dvs alla trådar) börjar exekvera det nya programmet.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="TrådarOchMultiprocessorer">
		<Question>
			Vad innebär gängschemaläggning?
		</Question>
		<Answer>
			Det innebär att alla trådar i en process kör samtidigt på olika CPU:er. Alla CPU:er byter också process samtidigt. Om en tråd blir blockerad så blir dess CPU idle så att inga andra trådar kan köras.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="TrådarOchMultiprocessorer">
		<Question>
			Hur kan man implementera lås på multiprocessorer?
		</Question>
		<Answer>
			Antag att [i]lock_ptr[/i] är adressen som vill låsa.
			Lås:
			[block]
lock: test_and_set tmp, (lock_ptr)
      branch_not_zero tmp, lock[/block]Lås upp:
      		[block]
unlock: store (lock_ptr), 0[/block]Där [i]test_and_set tmp (lock_ptr)[/i] är en maskininstruktion som:
      		[ul]
      			[li]Skriver värdet 1 till minnet på adress [i]lock_ptr[/i].[/li]
      			[li]Läser in gamla värdet till registret [i]tmp[/i].[/li]
      			[li]Låser bussen så att ingen annan processor kommer emellan.[/li]
      		[/ul]Denna typ av lås, där man hoppar tillbaka och försöker igen kallas [i]spin-locks[/i]. Dessa lås är ej lämpliga för en-processormaskiner för att endast en annan process kan låsa upp låset (som ej kan köra samtidigt).
		</Answer>
	</TestQuestion>
	<TestQuestion Category="TrådarOchMultiprocessorer">
		<Question>
			Vad innebär falsk delning?
		</Question>
		<Answer>
			Det innebär när två olika CPU:er vill skriva till två olika variabler som ligger på samma sida/samam cache linje. Detta innebär att båda cacherna måste tömas. Det händer vanligare vid större sidor/cache linjer och händer till en viss grad i alla cachar i multiprocessorer.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="DistribueradeSystem">
		<Question>
			Vad är distribuerat system?
		</Question>
		<Answer>
			Det är ett system som består av ett antal datorer som är sammankopplade med nätverk som inte delar fysisk minne och samverkar för att lösa ett problem, dvs fungerar som en enhet.

			Termnologi som används när man diskuterar distribuerade system är:
			[ul]
				[li][b]Site:[/b] fysisk plats med en eller flera datorer.[/li]
				[li][b]Host:[/b] dator på en site.[/li]
				[li][b]Server:[/b] Dator som har en resurs/tillhandahåller en tjänst som en annan dator vill använda.[/li]
				[li][b]Klient:[/b] Datorn som utnyttjar en tjänst hos en server.[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="DistribueradeSystem">
		<Question>
			Ange olika anledningar varför man vill ha ett distribuerat system.
		</Question>
		<Answer>
			[ul]
				[li]Resursdelning.[/li]
				[li]Uppsnabbning.[/li]
				[li]Tillförlitlighet.[/li]
				[li]Kommunikation.[/li]
				[li]Pris-prestanda.[/li]
				[li]Inkrementell uppdatering.[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="DistribueradeSystem">
		<Question>
			Ange designmål när det kommer till distribuerade system.
		</Question>
		<Answer>
			[b]Transparens[/b]
			Att systemet är distribuerat inte syns för användaren. Det finns olika typer av Transparens:
			[ul]
				[li]Namntransparens – namnet beror inte på var objektet finns.[/li]
				[li]Platstransparens (location transparency) – man behöver inte veta var resurser finns[/li]
				[li]Flyttransparens – användaren märker inte om resurser flyttar[/li]
				[li]Replikationstransparens - användaren behöver inte fundera på om man arbetar men en lokal kopia[/li]
				[li]Samtidighetstransparens - man behöver inte veta om att någon annan använder resurser samtidigt[/li]
				[li]Parallelitetstransparens - man behöver inte veta om att ens program körs parallelt[/li]
			[/ul][b]Feltolerans[/b]
			[b]Skalbarhet[/b]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="DistribueradeSystem">
		<Question>
			Att använda sig av caching i distribuerade filsystem är problematisk, varför?
		</Question>
		<Answer>
			Det är för att filen som cachas kan ha ändrats av andra. Om flera cachar, med olika innehåller uppstår problem när man ska skriva till servern, vilken version ska användas? Det finns olika sätt hantera det som:

			[b]Sekvensiell semantik (UNIX-semantik)[/b]
			Det innebär att det logiskt sätt bara finns en kopia av varje fil. Denna semantik är svårt att implementera effektivit.

			[b]Sessionssemantik[/b]
			Det innebär att varje klient som har filen öppen logiskt sett har en lokal kopia. Ändringar görs till den lokala kopian och när filen stängs så skrivs kopian tillbaka till servern. AFS implementerar på ett ungefär denna semantik.

			[b]Immutable (oförändlig)[/b]
			Det innebär att filer inte ändras, utan varje nu version ersätter den gamla. Varje version har ett nummer.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="DistribueradeSystem">
		<Question>
			Ange olika Cachekonsistensmekanismer för distribuerade system.
		</Question>
		<Answer>
			[ul]
				[li]Write-through: Varje skriving skrivs direkt till servern.[/li]
				[li]Delayed write: Ändringar skrivs periodvist t.ex. efter 30 sek.[/li]
				[li]Write-on-close: Filen skrivs tillbaka när den stängs.[/li]
				[li]Centralierad kontrol.[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="DistribueradeSystem">
		<Question>
			Hur kan man implementera UNIX-semantik?
		</Question>
		<Answer>
			Varje klient får [i]tokens[/i] som ger rätt att använda en lokal kopia.
			[ul]
				[li]Flera klienter kan ha [i]lästokens[/i] till samma fil.[/li]
				[li]Om en klient har [i]skrivtoken[/i] till en fil får inga andra klienter ha några tokens till den filen.[/li]
				[li]Om man ej har token får man ej göra lokala operationer även om man har filen i cachen.[/li]
				[li]Det är servern som håller reda på alla tokens som delats ut.[/li]
			[/ul]Om en klient vill läsa en fil måste servern återkalla eventuellt utdelad skrivtoken:
			[ul]
				[li]Klient med skrivtoken ger ifrån sig detta tilsammans med alla nya data som den har skrivit.[/li]
				[li]Servern uppdaterar filen med dessa nya datan och skickar ändringarna/hela filen till klienten som ville läsa.[/li]
			[/ul]Om en klient vill skriva till en fil måste servern återkalla alla andra tokens.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="DistribueradeSystem">
		<Question>
			Vad för för- och nackdelar finns det för filservar med och utan tillstånd?
		</Question>
		<Answer>
			[b]Med tillstånd[/b]
			Fördelar:
			[ul]
				[li]Kortare meddelanden från klienten.[/li]
				[li]Kan ge bättre prestanda.[/li]
				[li]Readahead möjligt.[/li]
				[li]Lättare att koordinera idempotenta operationer (ger samma resultat oberoende av antalet upprepgningar).[/li]
				[li]Enklare att låsa filer.[/li]
			[/ul]Nackdelar:
			[ul]
				[li]Om klienten kraschar
					[ul]
						[li]Så kan filer bli öppna för evigt.[/li]
						[li]Tillståndsinformation ligger kvar på servern och kan ej tas bort (minnesläckor).[/li]
					[/ul]
				[/li]
				[li]
					Om servern kraschar
					[ul]
						[li]Information om t.ex. filoffset försviner för klienter med öppna filer.[/li]
						[li]Konsistensinformation (vilka klienter som har lokala kopior av filer) försvinner.[/li]
					[/ul]
				[/li]
			[/ul][b]Utan tillstånd[/b]
			Fördelar:
			[ul]
				[li]Feltolerans.[/li]
				[li]Att öppna/stänga filer behövs ej.[/li]
				[li]Kräver mindre minne för servern.[/li]
				[li]Inge begränsningar på antalet öppnma filer.[/li]
				[li]Inga problem om klienten kraschar.[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Synkronisering">
		<Question>
			Hur kan en pipe användas för synkronisering?
		</Question>
		<Answer>
			En pipe implementeras som en buffer i kärnan och har en fast storlek. Om en process vill skriva till en pipe vars buffer är full måste den vänta. Om en process vill läsa från en pipe vars buffer är tom måste den vänta. Detta är ett exempel på [i]synkronisering[/i].
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Synkronisering">
		<Question>
			Vad är en semafor?
		</Question>
		<Answer>
			En [i]semafor[/i] är en räknare som har operationerna:
			[ul]
				[li]Upp: öka värdet med ett.[/li]
				[li]ner: Minska värdet med ett om det ej är noll, om så fall, vänta.[/li]
			[/ul] En semaforoperation är atomisk, dvs att ingen annan tråd eller process kan komma emellan.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Synkronisering">
		<Question>
			Vad innebär ett race-condition?
		</Question>
		<Answer>
			Det innebär att två processer (eller trådar) tävlar om samma resurs.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Synkronisering">
		<Question>
			Vad är en kritisk sektion?
		</Question>
		<Answer>
			Det är en sektion av kod där flera processer accessar samma resurs.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Synkronisering">
		<Question>
			Vad är ett baklås (deadlock)?
		</Question>
		<Answer>
			Det innebär att en mängd processer [math]P[/math] så att varje [math]p in P[/math] väntar (är blockerad) på att någon händelse som endast kan orsakas av någon [math]p' in P[/math] körs. Orsaker till att någon process väntar är t.ex.:
			[ul]
				[li]I/O enheter: [math]p[/math] vill ha skrivaren som [math]p'[/math] har reserverat.[/li]
				[li]Ömsesidig uteslutning: [math]p[/math] vill öppna en fil som [math]p'[/math] låst.[/li]
				[li]Andra resurser: [math]p[/math] vill starta en process men processtabellen är full.[/li]
				[li]Kommunikation: [math]p[/math] väntar på att [math]p'[/math] ska skicka ett meddelande.[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Synkronisering">
		<Question>
			Vad är Coffmans villkor (för baklås)?
		</Question>
		<Answer>
			[ul]
				[li]Ömsesidig uteslutning: Endast en process åt gången kan använda en resurs.[/li]
				[li]Behåll och vänta: En process kan behålla (reserverade) resurser medan den vänta på att få andra.[/li]
				[li]Ingen pre-emption (konfiskering): Resurser kan inte tas ifrån en process.[/li]
				[li]Cirkulär väntan: Det måste finnas en cykel av processer där varje process väntar på att få en resurs av nästa.[/li]
			[/ul]Resurser är saker som t.ex.: minne, diskenheter, lås, semaforer och meddelanden.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Synkronisering">
		<Question>
			Vad kan man göra för att hantera baklås?
		</Question>
		<Answer>
			[b]Gör ingenting (strutsalgoritmen)[/b]
			Anledingen för detta är att det är dyrt och krångligt att undvika/upptäcka baklås. Används i bland annat Unix.

			[b]Detektering och återhämtning[/b]
			Systemet håller reda på resursallokering och letar efter cykler. Används i VMS.

			[b]Undvikande grnom försiktighet[/b]
			Kräver begräsningar för användarprocesser.

			[b]Förhindrade genom elimination av nödvändigt villkor[/b]
			Kan inte alltid genomföras fullt ut, men kan användas för att eliminera vissa källor till baklås.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Synkronisering">
		<Question>
			Hur kan man upptäcka baklås?
		</Question>
		<Answer>
			[b]Om det bara finns en enhet av varje resurs[/b]
			Då är det ganska enkelt att implementera. Systemet håller reda på för varje process vilka resurser den har och vilka den väntar på. Om det finns cykler, så kan baklås existera. Det finns algoritmer som kan hitta cykler i linjär tid.

			[b]Om det finns fler av varje resurs[/b]
			Då blir det mycket mer komplicerat. En process som väntar på att få en resurs väntar på någon av de processer som ahr resursen ska släppa den. Den cirkulära väntan kan komma att brytas av att processer som är klara med användingen av en resurs släpper sina resurser. En lösning är att konstruera Bankiralgoritm tabeller.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Synkronisering">
		<Question>
			Hur kan man återhämta sig ifrån baklås?
		</Question>
		<Answer>
			[b]Inför pre-emption (konfiskation)[/b]
			Det innebär att man tar ifrån en process en resurs. T.ex. för fysisk minne kan man göra en page-out. 

			[b]Roll-back (tillbakarullning)[/b]
			Det innebär att man går tillbaka till en tidigare punkt i exekveringen och väljer en annan schemaläggning. Vissa operationer som har sidoeffekter t.ex. I/O är problematiskt att rulla tillbaka.

			[b]Döda processer[/b]
			Någon av de låste processerna slås hjäl. Detta garanterar ej att baklåset låses upp direkt, men om fortsätter att slå hjäl processer så kommer det tillslut att låsas upp.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Synkronisering">
		<Question>
			Hur fungerar Bankiralgoritmen?
		</Question>
		<Answer>
			Det bygger på att systemet kan kontrollera schemaläggningen av processerna. Varje process måste anmäla sitt maximala resursbehov i förvag. Systemet ska alltid befinna sig i ett säker tillstånd vilket defineras som: Det finns en ordning i vilken procsserna kan köras som inte leder till låsning även om alla processer utnyttjar hela sitt maximala resursbehov. Om en process kommer med en begäran som skulle leda till att systemet hamnar i ett osäker tillstånd, så körs en annan process istället. Den uppskjutna begäran uppfylls senare.

			Algoritmen går oftast inte att använda för i många fall så känner inte en process till hela sitt resursbehov innan programmet börjar exekverar.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Synkronisering">
		<Question>
			Vad kan man göra för att förhinda baklås?
		</Question>
		<Answer>
			Se till att någon av Coffmans fyra villkor inte gäller.
			[ul]
				[li]Ej tillåta att en processer äger en resurs exklusivt utan alla resurser ska kunna delas. I de flesta faller går det inte att göra, men i vissa fall t.ex. med skrivare går det där man låter en process fungera som resurshanterare.[/li]
				[li]Behåll och vänta: Kräv att en process släpper alla resurser när den begär en ny eller att den begär alla resurser på samma gång.[/li]
				[li]Ingen konfiskering: Vissa resurser kan konfiskeras som t.ex. fysisk minne och processorn (om avbrytade schemaläggning används).[/li]
				[li]Cirkulär väntan: Ge alla resurser ett nummer. Det är bara tillåtet att allokera resurser i en ökande ordning. En av de mest populära villkoren som man försöker ge sig på.[/li]
			[/ul]
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Synkronisering">
		<Question>
			Antag att man har lås för flera kritiska sektioner och flera processer använder flera av de kritiska sektionerna. Vad bör man då göra?
		</Question>
		<Answer>
			Att man låser sektionerna i samma ordning, detta undvilker att baklås uppstår.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Synkronisering">
		<Question>
			Vad innebär livelock?
		</Question>
		<Answer>
			Det innebär att en grupp av processer som exkeverar inte kommer vidare eftersom de hela tiden synkroniserar med varandra. Detta är svårt att upptäcka eftersom procsserna fortfarnade exekverar.
		</Answer>
	</TestQuestion>
	<TestQuestion Category="Synkronisering">
		<Question>
			Hur fungerar logiska klockor?
		</Question>
		<Answer>
			[ul]
				[li]Varje process [math]i[/math] har en egen logisk klocka [math]T_i[/math].[/li]
				[li]Vid varje lokal händelse i processen så sätts [math]T_i = T_i + 1[/math].[/li]
				[li]När ett meddelande skickas till en anna process så uppdateras [math]T_i[/math] och skickas med meddelandet.[/li]
				[li]När ett meddelande tas emot så uppdateras den lokala tiden till [math]max(text{lokaltid}+1, text{meddelandetid}+1)[/math][/li]	
			[/ul]Detta ger en kausal ordning, dvs omen händelse [math]A[/math] orskat en händelse [math]B[/math] (direkt eller indirekt) så är tidsstämpeln för [math]A[/math] mindre än tidsstämpeln för [math]B[/math].

			En total ordning av händelser kan uppnås om man t.ex. använder (unikt) ID för processer för att ordna händelser med samma tidsstämpel.
		</Answer>
	</TestQuestion>
</Test>
